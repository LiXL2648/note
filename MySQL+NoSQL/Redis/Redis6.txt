一、Redis_事务_秒杀案例
	1. 计数器和人员记录
		① 产品key："sk:" + prodId + ":num";
		② 用户key："sk:" + prodId + ":user"
	2. 秒杀并发模拟--Jmeter
		① 安装
			A. 下载官网：https://jmeter.apache.org/
			B. 安装，直接解压apache-jmeter-5.4.1.zip到指定目录
			C. 切换语言：Options -> Choose Language -> Chinese(Simplified)
		① 压测示例
			A. 添加线程组：新建测试计划，右键测试计划，选择添加 -> 线程（用户） -> 线程组
			B. 在线程组中，设置线程属性
				a. 线程数：200（两百个用户同时进行访问）
				b. Ramp-Up时间（秒）：1（1秒内启动200个线程）
				c. 循环次数：
					a. 勾选永远：则会一直循环压测下去，知道点击STOP按钮
					b. 输入100： 每个线程发送一百次请求
				d. 至此，一秒内有两万个请求进行测试
			A. 添加HTTP请求：右键线程组，选择添加 -> 取样器 -> HTTP请求
			B. 在HTTP请求中，在 基本 -> Web服务器 中设置请求信息
				a. 协议：http
				b. 服务器名称或IP：localhost
				c. 端口：8090
				d. HTTP请求：GET
				e. 路径：/secondKill?prodId=1
			C. 添加查看测试结果：
				a. 结果树
					(1) 右键线程组，选择添加 -> 监听器 -> 查看结果树
					(2) 在查看结果树中，可以查看每个请求是否成功，以及返回的数据
				b. 汇总报告
					(1) 右键线程组，选择添加 -> 监听器 -> 汇总报告
					(2) 在汇总报告中，可以查看各种指标，比如多少个样本，最大和最小响应时间等。
				c. 聚合报告
					(1) 右键线程组，选择添加 -> 监听器 -> 聚合报告
					(2) 聚合报告，可以查看各种指标，比如样本数，平均值，中位数等。
			D. 点击工具栏的开始图标，开始压力测试
	3. 在高并发下出现超卖问题，利用乐观锁淘汰用户
		public String secondKill(String prodId) {

			// 判断是否为空
			if (prodId == null || prodId.isEmpty()) {
				System.out.println("请输入产品编号");
				return "请输入产品编号";
			}

			// 获取用户ID
			String userId = new Random().nextInt(100000) + "";

			// 产品key和用户key
			String prodKey = "sk:" + prodId + ":num";
			String userKey = "sk:" + prodId + ":user";

			// 连接redis
			try (Jedis jedis = new Jedis("10.10.0.26", 6379)) {

				// 判断秒杀产品是否存在
				String prodValue = jedis.get(prodKey);
				if (prodValue == null) {
					System.out.println("秒杀未开始");
					return "秒杀未开始";
				}

				// 判断秒杀是否结束
				if (Integer.parseInt(jedis.get(prodKey)) <= 0) {
					System.out.println("秒杀已结束");
					return "秒杀已结束";
				}

				// 判断用户是否重复参与秒杀
				if (jedis.sismember(userKey, userId)) {
					System.out.println("不能重复参与秒杀");
					return "不能重复参与秒杀";
				}

				// 秒杀过程
				// 监视库存
				jedis.watch(prodKey);

				// 开启事务
				Transaction multi = jedis.multi();

				// 组队操作
				multi.decr(prodKey);
				multi.sadd(userKey, userId);

				// 执行
				List<Object> exec = multi.exec();

				if (exec == null || exec.size() == 0) {
					System.out.println("秒杀失败");
					return "秒杀失败";
				}

				System.out.println("秒杀成功");
				return "秒杀成功";
			}
		}
		4. 连接超时，通过连接池解决
			① 节省每次连接redis服务带来的消耗，把连接好的实例反复利用。
			② 链接池参数
				A. MaxTotal：控制一个pool可分配多少个jedis实例，通过pool.getResource()来获取；如果赋值为-1，则表示不限制；如果pool已经分配了
				MaxTotal个jedis实例，则此时pool的状态为exhausted。
				B. maxIdle：控制一个pool最多有多少个状态为idle(空闲)的jedis实例；
				C. MaxWaitMillis：表示当borrow一个jedis实例时，最大的等待毫秒数，如果超过等待时间，则直接抛JedisConnectionException；
				D. testOnBorrow：获得一个jedis实例的时候是否检查连接可用性（ping()）；如果为true，则得到的jedis实例均是可用的；
			③ 代码
				import redis.clients.jedis.JedisPool;
				import redis.clients.jedis.JedisPoolConfig;

				public class JedisPoolUtil {

					private static volatile JedisPool jedisPool = null;

					private static final String HOST = "10.10.0.26";

					private static final Integer PORT = 6379;

					private static final Integer TIMEOUT = 60000;

					private JedisPoolUtil() {}

					public static JedisPool getJedisPool() {
						if (jedisPool == null) {
							synchronized (JedisPoolUtil.class) {
								if (jedisPool == null) {
									JedisPoolConfig poolConfig = new JedisPoolConfig();
									poolConfig.setMaxTotal(200);
									poolConfig.setMaxIdle(32);
									poolConfig.setMaxWaitMillis(100 * 1000);
									poolConfig.setBlockWhenExhausted(true);
									poolConfig.setTestOnBorrow(true);
									jedisPool = new JedisPool(poolConfig, HOST, PORT, TIMEOUT);
								}
							}
						}

						return jedisPool;
					}
				}
		5. 解决库存遗留问题
			① 已经秒光，可是还有库存。原因，就是乐观锁导致很多请求都失败。先点的没秒到，后点的可能秒到了。
			② LUA脚本
				A. Lua 是一个小巧的脚本语言，Lua脚本可以很容易的被C/C++ 代码调用，也可以反过来调用C/C++的函数，Lua并没有提供强大的库，一个完整的Lua
				解释器不过200k，所以Lua不适合作为开发独立应用程序的语言，而是作为嵌入式脚本语言。
				B. 很多应用程序、游戏使用LUA作为自己的嵌入式脚本语言，以此来实现可配置性、可扩展性。
				C. 这其中包括魔兽争霸地图、魔兽世界、博德之门、愤怒的小鸟等众多游戏插件或外挂。https://www.w3cschool.cn/lua/
			③ LUA脚本在Redis中的优势
				A. 将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数。提升性能。
				B. LUA脚本是类似redis事务，有一定的原子性，不会被其他命令插队，可以完成一些redis事务性的操作。
				C. 但是注意redis的lua脚本功能，只有在Redis 2.6以上的版本才可以使用。
				D. 利用lua脚本淘汰用户，解决超卖问题。
				E. redis 2.6版本以后，通过lua脚本解决争抢问题，实际上是redis 利用其单线程的特性，用任务队列的方式解决多任务并发问题。
			④ 代码
				public String secondKillByScript(String prodId) {
					// 判断是否为空
					if (prodId == null || prodId.isEmpty()) {
						System.out.println("请输入产品编号");
						return "请输入产品编号";
					}

					// 获取用户ID
					String userId = new Random().nextInt(100000) + "";

					// 连接redis
					try (Jedis jedis = JedisPoolUtil.getJedisPool().getResource()) {

						// 编写 LUA 脚本
						String script = "local userId = KEYS[1];\n" +
								"local prodId = KEYS[2];\n" +
								"local prodKey = \"sk:\"..prodId..\":num\";\n" +
								"local userKey = \"sk:\"..prodId..\":user\";\n" +
								"local prodNum = redis.call(\"get\", prodKey);\n" +
								"if prodNum == false then\n" +
								"\treturn 0;\n" +
								"end\n" +
								"local userExists = redis.call(\"sismember\", userKey, userId);\n" +
								"if tonumber(userExists) == 1 then\n" +
								"\treturn 3;\n" +
								"end\n" +
								"if tonumber(prodNum) <= 0 then\n" +
								"\treturn 2;\n" +
								"else\n" +
								"\tredis.call(\"decr\", prodKey);\n" +
								"\tredis.call(\"sadd\", userKey, userId);\n" +
								"end\n" +
								"return 1;";

						// 加载 LUA 脚本
						String sha1 = jedis.scriptLoad(script);

						// 执行 LUA 脚本
						Object evalsha = jedis.evalsha(sha1, 2, userId, prodId);
						int result = Integer.parseInt(evalsha.toString());
						if (result == 0) {
							System.out.println("秒杀未开始");
							return "秒杀未开始";
						} else if (result == 2) {
							System.out.println("秒杀已结束");
							return "秒杀已结束";
						} else if (result == 3) {
							System.out.println("不能重复参与秒杀");
							return "不能重复参与秒杀";
						} else if (result == 1) {
							System.out.println("秒杀成功");
							return "秒杀成功";
						} else {
							System.out.println("秒杀失败");
							return "秒杀失败";
						}
					}
				}
二、Redis集群
	1. 问题
		① 容量不够，redis如何进行扩容？
		② 并发写操作， redis如何分摊？
		③ 另外，主从模式，薪火相传模式，主机宕机，导致ip地址发生变化，应用程序中配置需要修改对应的主机地址、端口等信息。
		④ 之前通过代理主机来解决，但是redis3.0中提供了解决方案。就是无中心化集群配置。
	2. 什么是集群
		① Redis 集群实现了对Redis的水平扩容，即启动N个redis节点，将整个数据库分布存储在这N个节点中，每个节点存储总数据的1/N。
		② Redis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯，
		集群也可以继续处理命令请求。
	3. 制作6个实例
		① 删除持久化数据，将rdb,aof文件都删除掉
		② 配置基本信息
			daemonize yes
			pidfile /var/run/redis_6379.pid
			port 6379
			logfile ""
			dbfilename dump.rdb
			appendonly no
		③ redis cluster配置修改		
			include /usr/local/redis/conf/redis_cluster.conf
			port 6379
			pidfile "/var/run/redis_6379.pid"
			dbfilename "dump6379.rdb"
			cluster-enabled yes
			cluster-config-file nodes-6379.conf
			cluster-node-timeout 15000
		④ 修改好redis6379.conf文件，拷贝多个redis.conf文件，并且进行修改
		⑤ 将六个节点合成一个集群
			A. 确保所有redis实例启动后，nodes-xxxx.conf文件都生成正常
			B. 命令：
				redis-cli --cluster create --cluster-replicas 1 192.168.11.101:6379 192.168.11.101:6380 192.168.11.101:6381 
				192.168.11.101:6389 192.168.11.101:6390 192.168.11.101:6391
			C. 此处不要用127.0.0.1，用真实IP地址
			D. replicas 1 采用最简单的方式配置集群，一台主机，一台从机，正好三组。
	4. 登录：
		① -c 采用集群策略连接，设置数据会自动切换到相应的写主机
		② 举例：redis-cli -c -p 6379
		③ 通过 cluster nodes 命令查看集群信息
	5. redis cluster 如何分配这六个节点
		① 一个集群至少要有三个主节点。
		② 选项 --cluster-replicas 1 表示我们希望为集群中的每个主节点创建一个从节点。
		③ 分配原则尽量保证每个主数据库运行在不同的IP地址，每个从库和主库不在一个IP地址上。
	6. 什么是slots
		① 一个 Redis 集群包含 16384 个插槽（hash slot）， 数据库中的每个键都属于这 16384 个插槽的其中一个
		② 集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和
		③ 集群中的每个节点负责处理一部分插槽。 举个例子， 如果一个集群可以有主节点， 其中：
			A. 节点 A 负责处理 0 号至 5460 号插槽。
			B. 节点 B 负责处理 5461 号至 10922 号插槽。
			C. 节点 C 负责处理 10923 号至 16383 号插槽。
	7. 在集群中录入值
		① 在redis-cli每次录入、查询键值，redis都会计算出该key应该送往的插槽，如果不是该客户端对应服务器的插槽，redis会报错，并告知应前往的
		redis实例地址和端口。
		② redis-cli客户端提供了 –c 参数实现自动重定向。
		③ 如 redis-cli  -c –p 6379 登入后，再录入、查询键值对可以自动重定向。
		④ 不在一个slot下的键值，是不能使用mget,mset等多键操作。
			mset k1 v1 k2 v2 k3 v3
			(error)CROSSSLOT Keys in request don't hash to the same slot
		⑤ 可以通过{}来定义组的概念，从而使key中{}内相同内容的键值对放到一个slot中去。
			mset k1{c} v1 k2{c} v2 k3{c} v3
	8. 查询集群中的值
		① CLUSTER GETKEYSINSLOT <slot><count>：返回 count 个 slot 槽中的键。
		② CLUSTER keyslot cust：返回cust组所在的插槽数
		③ CLUSTER countkeysinslot 4847：返回所在插槽数 key 的数量
	9. 故障恢复
		① 主节点下线，从节点自动升为主节点
		② 主节点恢复后，主节点回来变成从机
		③ 所有某一段插槽的主从节点都宕掉，redis服务是否还能继续
			A. 如果某一段插槽的主从都挂掉，而cluster-require-full-coverage 为yes ，那么 ，整个集群都挂掉
			B. 如果某一段插槽的主从都挂掉，而cluster-require-full-coverage 为no ，那么，该插槽数据全都不能使用，也无法存储。
			C. redis.conf中的参数  cluster-require-full-coverage
	10. 集群的Jedis开发
		① 即使连接的不是主机，集群会自动切换主机存储。主机写，从机读。
		② 无中心化主从集群。无论从哪台主机写的数据，其他主机上都能读到数据。
		③ 代码：
			public void testJedisCluster() {

				Set<HostAndPort> nodes = new HashSet<>();
				nodes.add(new HostAndPort("192.168.230.24", 6380));
				nodes.add(new HostAndPort("192.168.230.24", 6379));
				nodes.add(new HostAndPort("192.168.230.24", 6381));
				nodes.add(new HostAndPort("192.168.230.24", 6389));
				nodes.add(new HostAndPort("192.168.230.24", 6390));
				nodes.add(new HostAndPort("192.168.230.24", 6391));
				JedisCluster jedisCluster = new JedisCluster(nodes);

				String name1 = jedisCluster.get("name1");
				System.out.println(name1);
			}
	11. SpringBoot 整合 Redis 集群
		① 引入依赖
			<dependency>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-starter-data-redis</artifactId>
			</dependency>
		② 配置yml
			spring:
			  redis:
				timeout: 60000 #连接超时时间（毫秒）
				database: 0 #Redis数据库索引（默认为0）
				cluster: # 集群节点
				  nodes:
					- 192.168.230.24:6379
					- 192.168.230.24:6380
					- 192.168.230.24:6381
					- 192.168.230.24:6389
					- 192.168.230.24:6390
					- 192.168.230.24:6391
				lettuce:
				  pool:
					max-active: 1000  #连接池最大连接数（使用负值表示没有限制）
					max-idle: 10 # 连接池中的最大空闲连接
					min-idle: 5 # 连接池中的最小空闲连接
					max-wait: -1 # 连接池最大阻塞等待时间（使用负值表示没有限制）
		③ 编写配置类
			import com.fasterxml.jackson.annotation.JsonAutoDetect;
			import com.fasterxml.jackson.annotation.PropertyAccessor;
			import com.fasterxml.jackson.databind.ObjectMapper;
			import org.springframework.cache.CacheManager;
			import org.springframework.cache.annotation.CachingConfigurerSupport;
			import org.springframework.cache.annotation.EnableCaching;
			import org.springframework.context.annotation.Bean;
			import org.springframework.context.annotation.Configuration;
			import org.springframework.context.annotation.Primary;
			import org.springframework.data.redis.cache.RedisCacheConfiguration;
			import org.springframework.data.redis.cache.RedisCacheManager;
			import org.springframework.data.redis.connection.RedisConnectionFactory;
			import org.springframework.data.redis.core.RedisTemplate;
			import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
			import org.springframework.data.redis.serializer.RedisSerializationContext;
			import org.springframework.data.redis.serializer.RedisSerializer;
			import org.springframework.data.redis.serializer.StringRedisSerializer;

			@EnableCaching
			@Configuration
			public class MyRedisConfig extends CachingConfigurerSupport {

				@Bean
				@Primary
				public RedisTemplate<Object, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory) {
					RedisTemplate<Object, Object> redisTemplate = new RedisTemplate<>();
					redisTemplate.setConnectionFactory(redisConnectionFactory);

					ObjectMapper objectMapper = new ObjectMapper();
					objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);

					Jackson2JsonRedisSerializer<Object> jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer<>(Object.class);
					jackson2JsonRedisSerializer.setObjectMapper(objectMapper);

					StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
					redisTemplate.setKeySerializer(stringRedisSerializer);
					redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);
					redisTemplate.setHashValueSerializer(stringRedisSerializer);
					redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer);

					return redisTemplate;
				}

				@Bean
				@Primary
				public CacheManager cacheManager(RedisConnectionFactory factory) {
					RedisSerializer<String> redisSerializer = new StringRedisSerializer();
					Jackson2JsonRedisSerializer<Object> jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer<>(Object.class);
					ObjectMapper objectMapper = new ObjectMapper();
					objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
					jackson2JsonRedisSerializer.setObjectMapper(objectMapper);

					RedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration.defaultCacheConfig()
							.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer))
							.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer))
							.disableCachingNullValues();

					return RedisCacheManager.builder(factory)
							.cacheDefaults(redisCacheConfiguration)
							.build();
				}
			}
		④ 测试类
			@Test
			public void testRedisTemplate() {
				redisTemplate.opsForValue().set("name5", "WangHP");

				System.out.println(redisTemplate.opsForValue().get("name5"));
			}
	12. Redis 集群提供了以下好处
		① 实现扩容
		② 分摊压力
		③ 无中心配置相对简单
	13. Redis 集群的不足
		① 多键操作是不被支持的 
		② 多键的Redis事务是不被支持的。lua脚本不被支持
		③ 由于集群方案出现较晚，很多公司已经采用了其他的集群方案，而代理或者客户端分片的方案想要迁移至redis cluster，
		需要整体迁移而不是逐步过渡，复杂度较大。
三、Redisson
	1. 本地锁在分布式下的问题
		如果是单机情况下，线程之间共享内存，只要使用线程锁就可以解决并发问题。但如果是分布式情况下，线程锁就无法起到作用了，这时候就要用到分布式锁来解决
	2. 分布式锁原理与使用
		① 原理：多个进程在一个公共区域获取锁，如果先获取锁，就先执行逻辑，否则就等待，直到其他进程释放锁。
		② redis客户端使用：
			A. 命令：SET key value [EX seconds] [PX milliseconds] [NX|XX]
			B. 选项说明
				a. EX seconds：设置键key的过期时间，单位时秒
				b. PX milliseconds：设置键key的过期时间，单位时毫秒
				c. NX：只有键key不存在的时候才会设置key的值
				d. XX：只有键key存在的时候才会设置key的值
			C. 举例：set lock 1 NX
		③ Java 使用：
			A. 方法：boolean redisTemplate.opsForValue.setIfAbsent(String key, String value)
			B. 举例：
				public String testSetNx() {
					boolean lock = redisTemplate.opsForValue.setIfAbsent("lock", "1");
					if(lock) {
						// 加锁成功，执行业务代码，查询数据库，并将业务代码执行的结果保存到缓存
						执行业务代码……
						// 释放锁
						redisTemplate.delete("lock");
					} else {
						// 加锁失败，休眠100ms，重试
						return testSetNx(); // 自旋
					}
				}
		
	3. 分布式锁演进
		① 阶段一：
										+-------+
										| redis |
										+-------+
											↓
							  +----------------------------+				
							  | 获取锁，setnx("lock", "1") | <----------+
							  +----------------------------+			|
									返回OK	|	返回null				| 等待100ms，自旋重试
							+--------------------------------+			|
							↓								 ↓			|
					   +----------+					   +------------+	|
					   | 获取到锁 |					   | 没获取到锁 | --+
					   +----------+					   +------------+
							↓
					   +----------+			
					   | 执行业务 |
					   +----------+	
							↓
					   +----------+			
					   |  删除锁  |
					   +----------+
							↓
					   +----------+			
					   |   结束   |
					   +----------+
			A. 问题：setnx 获取了锁，业务代码异常或者程序在执行过程中宕机。没有执行删除锁逻辑，这就造成了死锁。
			B. 解决：设置锁的自动过期，即使没有删除，会自动删除
			C. 举例：
				public String testSetNx() {
					boolean lock = redisTemplate.opsForValue.setIfAbsent("lock", "1");
					if(lock) {
						// 设置过期时间
						redisTemplate.expire("lock", 30, TimeUnit.SECEND);
						// 加锁成功，执行业务代码，查询数据库，并将业务代码执行的结果保存到缓存
						执行业务代码……
						// 释放锁
						redisTemplate.delete("lock");
					} else {
						// 加锁失败，休眠100ms，重试
						return testSetNx(); // 自旋
					}
				}
		② 阶段二：
										+-------+
										| redis |
										+-------+
											↓
							  +----------------------------+				
							  | 获取锁，setnx("lock", "1") | <----------+
							  +----------------------------+			|
									返回OK	|	返回null				| 等待100ms，自旋重试
							+--------------------------------+			|
							↓								 ↓			|
					   +----------+					   +------------+	|
					   | 获取到锁 |					   | 没获取到锁 | --+
					   +----------+					   +------------+
							↓
					 +--------------+
					 | 设置过期时间 |
					 +--------------+
							↓
					   +----------+			
					   | 执行业务 |
					   +----------+	
							↓
					   +----------+			
					   |  删除锁  |
					   +----------+
							↓
					   +----------+			
					   |   结束   |
					   +----------+
			A. 问题：setnx 获取了锁，正要去设置过期时间，宕机，又出现死锁
			B. 解决：设置过期时间和占位必须是原子的，redis支持使用 setnx ex 命令
			C. 命令：set lock 1 EX 30 NX
			D. 举例：
				public String testSetNx() {
					boolean lock = redisTemplate.opsForValue.setIfAbsent("lock", "1", 30, TimeUnit.SECEND);
					if(lock) {
						// 设置过期时间，必须是原子操作
						// redisTemplate.expire("lock", 30, TimeUnit.SECEND);
						// 加锁成功，执行业务代码，查询数据库，并将业务代码执行的结果保存到缓存
						执行业务代码……
						// 释放锁
						redisTemplate.delete("lock");
					} else {
						// 加锁失败，休眠100ms，重试
						return testSetNx(); // 自旋
					}
				}
		③ 阶段三：
											+-------+
											| redis |
											+-------+
												↓
							  +----------------------------------+				
							  | 获取锁，setnxex("lock", "1", 30) | <------------+
							  +----------------------------------+				|
										返回OK	|	返回null					| 等待100ms，自旋重试
							+--------------------------------------+			|
							↓									   ↓			|
					   +----------+					   		+------------+		|
					   | 获取到锁 |					   		| 没获取到锁 | -----+
					   +----------+					   		+------------+
							↓
					   +----------+			
					   | 执行业务 |
					   +----------+	
							↓
					   +----------+			
					   |  删除锁  |
					   +----------+
							↓
					   +----------+			
					   |   结束   |
					   +----------+
			A. 问题：如果由于业务时间超长，锁自己过期了，直接删除锁，有可能把别人正在持有的锁删除了
			B. 解决：占锁的时候，值指定为uuid，每个人匹配是自己的锁才删除
			C. 举例：
				public String testSetNx() {
					String uuid = UUID.randomUUID().toString();
					boolean lock = redisTemplate.opsForValue.setIfAbsent("lock", uuid, 30, TimeUnit.SECEND);
					if(lock) {
						// 设置过期时间，必须是原子操作
						// redisTemplate.expire("lock", 30, TimeUnit.SECEND);
						// 加锁成功，执行业务代码，查询数据库，并将业务代码执行的结果保存到缓存
						执行业务代码……
						// 释放锁，匹配是自己的锁才删除
						// redisTemplate.delete(""lock);
						String lockValue = redisTemplate.opsForValue.get("lock");
						if(uuid.equals(lockValue)) {
							redisTemplate.delete("lock");
						}
					} else {
						// 加锁失败，休眠100ms，重试
						return testSetNx(); // 自旋
					}
				}
		④ 阶段四：
											+-------+
											| redis |
											+-------+
												↓
							  +-----------------------------------+				
							  | 获取锁，setnxex("lock", UUID, 30) | <------------+
							  +-----------------------------------+				 |
										返回OK	|	返回null					 | 等待100ms，自旋重试
							+---------------------------------------+			 |
							↓									    ↓			 |
					   +----------+					   		 +------------+		 |
					   | 获取到锁 |					   		 | 没获取到锁 | -----+
					   +----------+					   		 +------------+
							↓
					   +----------+			
					   | 执行业务 |
					   +----------+	
							↓
				   +------------------+		  +--------+	
				   | 获取当前锁的值， | ----> | 删除锁 |
				   | 如果是之前的UUID |		  +--------+
			       +------------------+
							↓
					   +----------+			
					   |   结束   |
					   +----------+
			A. 问题：如果正好判断是当前值，正要删除的时候，锁已经过期，别人已经设置到了新的值。那我们删除的是别人的锁
			B. 删除锁必须保证原子性，使用redis + Lua 脚本完成
			C. 举例：
				public String testSetNx() {
					String uuid = UUID.randomUUID().toString();
					boolean lock = redisTemplate.opsForValue.setIfAbsent("lock", uuid, 30, TimeUnit.SECEND);
					if(lock) {
						// 设置过期时间，必须是原子操作
						// redisTemplate.expire("lock", 30, TimeUnit.SECEND);
						// 加锁成功，执行业务代码，查询数据库，并将业务代码执行的结果保存到缓存
						执行业务代码……
						// 释放锁，匹配是自己的锁才删除
						// redisTemplate.delete(""lock);
						// 获取值对比，对比成功再删除，必须是原子操作，使用redis + Lua脚本
						// String lockValue = redisTemplate.opsForValue.get("lock");
						// if(uuid.equals(lockValue)) {
						//	redisTemplate.delete("lock");
						// }
						String script = "if redis call('get', KEYS[1] == ARGV[1]) then return redis.call('del', KEYS[1])" + 
							"else return 0 end";
						redisTemplate.execute(new DefaultRedisScript<Long>(script, Long.class), Arrays.asList("lock"), uuid);
					} else {
						// 加锁失败，休眠100ms，重试
						return testSetNx(); // 自旋
					}
				}
		⑤ 分布式演进，阶段五，最终形态
											+-------+
											| redis |
											+-------+
												↓
							  +-----------------------------------+				
							  | 获取锁，setnxex("lock", UUID, 30) | <------------+
							  +-----------------------------------+				 |
										返回OK	|	返回null					 | 等待100ms，自旋重试
							+---------------------------------------+			 |
							↓									    ↓			 |
					   +----------+					   		 +------------+		 |
					   | 获取到锁 |					   		 | 没获取到锁 | -----+
					   +----------+					   		 +------------+
							↓
					   +----------+			
					   | 执行业务 |
					   +----------+	
							↓
				+----------------------+
				| 脚本解锁，保证原子行 |
			    +----------------------+
							↓
					   +----------+			
					   |   结束   |
					   +----------+
			A. LUA脚本: String script = "if redis call('get', KEYS[1] == ARGV[1]) then return redis.call('del', KEYS[1])" + 
							"else return 0 end";
			B. 保证加锁（占位+过期时间）和释放锁（判断+删除）的原子性。
			C. 问题：锁的自动续期
			D. 解决方法一：设置过期时间超长，执行完业务代码后，释放锁
			E. 举例：
				public String testSetNx() {
					String uuid = UUID.randomUUID().toString();
					boolean lock = redisTemplate.opsForValue.setIfAbsent("lock", uuid, 30, TimeUnit.SECEND);
					if(lock) {
						try {
							// 设置过期时间，必须是原子操作
							// redisTemplate.expire("lock", 30, TimeUnit.SECEND);
							// 加锁成功，执行业务代码，查询数据库，并将业务代码执行的结果保存到缓存
							执行业务代码……
							// 释放锁，匹配是自己的锁才删除
							// redisTemplate.delete(""lock);
							// 获取值对比，对比成功再删除，必须是原子操作，使用redis + Lua脚本
							// String lockValue = redisTemplate.opsForValue.get("lock");
							// if(uuid.equals(lockValue)) {
							//	redisTemplate.delete("lock");
							// }
							
						} finally {
							String script = "if redis call('get', KEYS[1] == ARGV[1]) then return redis.call('del', KEYS[1])" + 
								"else return 0 end";
							redisTemplate.execute(new DefaultRedisScript<Long>(script, Long.class), Arrays.asList("lock"), uuid);
						}
						
					} else {
						// 加锁失败，休眠100ms，重试
						return testSetNx(); // 自旋
					}
				}
	4. Redisson 简介、整合
		① 概述：Redisson是一个在 Redis 的基础上实现的 Java 驻内存数据网格（In-Memory Data Grid），它不仅提供了一系列的分布式的 Java 常用对象，
		还提供了许多分布式服务（BitSet、Set、Multimap、SortedSet、Map、List、Queue、BlockingQueue、Deque、BlockingDeque、Semaphore、Lock、
		AtomicLong、CountDowmLatch、Publish / Subscribe、Bloom filter、Remote service、Springcache、Executor service、Live Object service、
		Scheduler service），Redisson 提供了最简单和最便捷的方法，Redisson的宗旨是促进使用者对 Redis 的关注分离（Separation of Concern），
		从而让使用者能够将精力更集中地放在处理业务逻辑上。
		② Spring Boot 整合 Redisson
			A. pom.xml 引入 Redisson 依赖
				<dependency>
					<groupId>org.redisson</groupId>
					<artifactId>redisson</artifactId>
					<version>3.16.0</version>
				</dependency>
			B. YML 写配置
				spring:
				  redis:
					host: 10.10.0.26
					port: 6379
			C. 配置 Redisson
				a. 程序化配置方法，通过构建 Config 对象实例来实现
				b. 代码：
					@Configuration
					public class MyRedissonConfig {

						@Value("${spring.redis.host}")
						private String host;

						@Value("${spring.redis.port}")
						private int port;

						@Bean(destroyMethod = "shutdown")
						public RedissonClient redisson() {

							// 创建配置
							Config config = new Config();
							config.useSingleServer().setAddress("redis://" + host + ":" + port);

							// 根据Config 创建出 RedissonClient对象
							return Redisson.create(config);
						}
					}
		③ 可重入锁（Reentrant Lock）
			A. 基于Redisson 分布式可重入锁 RLock Java 对象实现了 java.concurrent.locks.Lock 接口。同时还提供了同步（Async）、反射式（Reative）
			和 RxJava2 标准的接口
			B. 负责存储这个分布式锁的 Redisson 节点宕机以后，如果这个锁正好处于锁住的状态时，这个锁会出现锁死的状元。为了避免这种情况的发生，
			Redisson内部提供了一个监控的看门狗，它的作用是在 Redisson 实例关闭前，不断地延长锁的有效期。默认情况下，看门狗检查锁的超时时间是
			30秒，也可以通过修改Config.lockWatchdogTimeout来另行指定。解决的问题：
				a. 锁的自动续期，如果业务超长，运行期间可自动给锁续上新的30s，不用担心业务长，锁自动过期被删除
				b. 加锁的业务只要运行完成，就不会给当前锁续期，即使不手动释放锁，锁也会默认在30s以后自动删除
			C. 另外Redisson还通过加锁的方法提供了leaseTime的参数来指定加锁的时间，超过这个时间后锁便自动解开了，一旦有处理业务的时间超过锁的
			自动过期时间，在业务还没执行完成时，锁被释放，等业务执行完成后尝试删除锁，会报错，即删除不是当前线程的锁，因此自动解锁时间一定要
			大于业务执行时间，但是此时的锁不会自动续期。
				a. 如果设置了锁的超时时间，就会给redis 发生Lua脚本，进行占锁，默认超时就是我们指定的时间，并且不会进行锁的自动续期。
				b. 如果未指定锁的超时时间，就会使用lockWatchdogTimeout看门狗的默认时间，只要占锁成功，就会启动一个定时任务，重新给锁设置过期时
				间，即看门狗时间，时间间隔为 LockWatchdogTimeout/3 s
			D. 最佳实战：使用超时自动解锁的方式加锁，lock.lock(30, TimeUnit.SECEND)，省掉自动续期的操作，并进行手动解锁
			E. 举例：
				public String hello() {

					// 获取一把锁，只要锁的名字一样，就是同一把锁
					RLock lock = redisson.getLock("hello-lock");

					// 加锁，阻塞式等待
					lock.lock();
					// lock.lock(10, TimeUnit.SECONDS);
					try {
						System.out.println("加锁成功，执行业务逻辑中……" + Thread.currentThread().getId());
						Thread.sleep(30000);
					} catch (Exception e) {
						e.printStackTrace();
					} finally {
						System.out.println("释放锁……" + Thread.currentThread().getId());
						lock.unlock();
					}
					return "Hello World";
				}
		④ 读写锁
			A. 保证一定能读到最新数据，修改期间，写锁是一个排他锁（互斥锁 / 独享锁），读锁是一个共享锁。
			B. 写锁没释放，就必须等待。
				a. 读 + 读：相当于无锁，只会在redis中记录好，所有当前读锁，都会同时加锁成功
				b. 写 + 读：等待写锁释放
				c. 写 + 写：阻塞等待
				d. 读 + 写：等待读锁的释放
			C. 举例：
				@RequestMapping("/write")
				public String write() {
					String uuid = UUID.randomUUID().toString();
					RReadWriteLock readWriteLock = redisson.getReadWriteLock("rw-lock");
					// 改数据加写锁
					RLock rLock = readWriteLock.writeLock();
					rLock.lock();
					try {
						Thread.sleep(30000);
						stringRedisTemplate.opsForValue().set("uuid", uuid);
					} catch (InterruptedException e) {
						e.printStackTrace();
					} finally {
						// 释放写锁
						rLock.unlock();
					}

					return uuid;
				}

				@RequestMapping("/read")
				public String read() {
					RReadWriteLock readWriteLock = redisson.getReadWriteLock("rw-lock");
					// 读数据加读锁
					RLock rLock = readWriteLock.readLock();
					rLock.lock();
					try {
						return stringRedisTemplate.opsForValue().get("uuid");
					} finally {
						// 释放读锁
						rLock.unlock();
					}
				}
		⑤ 闭锁：
			A. 应用场景：放假锁门，只有等所有班级都走完了，才能锁门
			B. 举例：
				@RequestMapping("/lockDoor")
				public String lockDoor() throws Exception {
					// 声明闭锁
					RCountDownLatch countDownLatch = redisson.getCountDownLatch("door-lock");
					// 等待几个锁的释放
					countDownLatch.trySetCount(5);
					// 等待闭锁都完成
					countDownLatch.await();

					return "放假了……";
				}

				@RequestMapping("/go/{id}")
				public String go(@PathVariable("id") Long id) {
					// 声明闭锁
					RCountDownLatch countDownLatch = redisson.getCountDownLatch("door-lock");
					// 技术减1
					countDownLatch.countDown();
					return id + "走了";
				}
		⑥ 信号量
			A. 信号量可用于访问限流，即先设置好信号量，每访问服务一次则减少一个信号，如果信号量为0，则其他访问需要等待信号量的释放。RSemaphore.acquire()
			是阻塞式等待，即信号量为0时，需要等待其他线程的释放，而使用RSemaphore.tryAcquire()，是非阻塞式等待，即信号量为0时，直接返回。
			B. 应用场景：车库停车，假如车库有三个车位，停一辆车减少一个车位，开走一辆车增加一个车位
				@RequestMapping("/park")
				public String park() throws Exception {
					RSemaphore semaphore = redisson.getSemaphore("park");
					// 获取一个信号，阻塞式等待
					// semaphore.acquire();
					// 非阻塞式等待
					boolean b = semaphore.tryAcquire();
					if (b) {
						// 执行业务
						return "park成功";
					}
					return "park失败";
				}

				@RequestMapping("/leave")
				public String leave() {
					RSemaphore semaphore = redisson.getSemaphore("park");
					// 释放一个信号
					semaphore.release();
					return "leave";
				}
四、缓存的常见问题
	1. 缓存一致性解决
		① 问题：缓存里面的数据如何和数据库保持一致性
		② 缓存一致性
			A. 双写模式			
									 +----------------------------------+
				+----------+		 |	+----------+		+--------+	|
				| 数据更新 | ------> | 	| 写数据库 | ----->	| 写缓存 |	|
				+----------+		 |	+----------+		+--------+	|
									 +----------------------------------+
							 读到的最新数据有延迟：最终一致性
							
							 关键点								   关键点
								|									 |
				+-------------+	|									 | +-----------+
				| 写数据库 -1 |	| ---------------------------------- | | 写缓存 -2 |
				+-------------+	|									 | +-----------+
								|									 |
								|									 |
								| +-------------+	   +-----------+ |
								| | 写数据库 -2 | ---- | 写缓存 -2 | | ------------>
								| +-------------+	   +-----------+ |
								|									 |
				a. 场景：由于卡顿等原因，导致写缓存2在最前面，写缓存1在后面就出现了不一致
				b. 脏数据问题：这是暂时性的脏数据问题，但是在数据稳定，缓存过期以后，又能得到最新的正确数据
				c. 解决方法，给每个并发操作加锁，等整个写的过程执行完成后，再释放锁。如果系统允许不一致性，那么也可以忽略这种情况，前提是
				需要给缓存加上过期时间，因此再解决方案产生的脏数据只是暂时性的。
			B. 失效模式	
									 +----------------------------------+
				+----------+		 |	+----------+		+--------+	|
				| 数据更新 | ------> | 	| 写数据库 | ----->	| 写缓存 |	|
				+----------+		 |	+----------+		+--------+	|
									 +----------------------------------+
									 
									  关键点								   关键点
										 |										 |
				+-------------+--------+ |										 |
				| 写数据库 -1 | 删缓存 | |										 |
				+-------------+--------+ |										 |
							+------------|---------------------------+---------+ |
							| 写数据库-2   			  	 			 |	删缓存 | |			 
							+------------|---------------------------+---------+ |
										 | +--------+------------+				 | +----------+
										 | | 读缓存 | 读数据库-1 |				 | | 更新缓存 |
										 | +--------+------------+				 | +----------+
										 |										 |
				a. 场景：当线程A写完数据库，并删除缓存后，线程B想写数据库，但是由于改操作持续的时间太长，还每写完数据库，线程C读了缓存，没有
				获取到数据，进而读数据库，但是由于卡顿，没有及时更新缓存，线程B写完数据，而线程C
				此时更新缓存的是线程A更新完的而线程B还没更新的数据。
				b. 解决方法，会写和读数据加上读写锁
		③ 缓存一致性方案
			A. 无论是双写模式，还是失效模式，都会导致缓存的不一致性问题，即多个实例同时更新会出现问题。
				a. 如果是用户维度数据（订单数据、用户数据），这种并发几率非常小，不用考虑这个问题，缓存数据加上过期时间，每隔一段时间触发读的
				主动更新即可。
				b. 如果是菜单、商品介绍等基础数据，也可以去使用canal订阅binlog的方式
				c. 缓存数据+过期时间也足够解决大部分业务对于缓存的要求
				d. 通过加锁保证并发读写，写写的时候按照顺序排好队，读读无所谓，所有适合使用读写锁（业务不关心脏数据，允许临时数据可忽略）
			B. 总结：
				a. 我们能放入缓存的数据本就不应该是实时性、一致性要求超高的。所以缓存数据的时候加上过期时间，保证每天拿到当前最新数据即可
				b. 我们不应该过度设计、增加系统的复杂性
				c. 遇到实时性、一致性要求高的数据，就应该查询数据库，即使速度慢点。
		④  canal
			A. 使用 Canal 更新缓存
				+---------------+						   +-------+
				|    业务代码   |						   | Redis |
				+---------------+						   +-------+
						↓									   ↑
				+---------------+						   +-------+
				| 更新 Database | 					 	   | canal |
				+---------------+						   +-------+
						|									   |
						|			  +--------+	订阅       |
						+------------ | Binlog | --------------+
									  +--------+
			B. 使用 Canal 进行数据异构
				+--------------+					+--------------+
				| 192.168.1.26 |					| 192.168.1.26 |
				| 访问记录表   |					|  商品信息表  |
				+--------------+					+--------------+
					   |									|
					   |	Binlog	  +-------+		Binlog	|
					   +------------- | Canal | ------------+
							订阅	  +-------+		订阅
										  |
										  ↓ 分析计算
									+------------+
									|  异构系统  |
									| 用户推荐表 |
									+-------------
										  ↑
										  |
									+------------+
									| 	  Web	 |
									+------------+
	2. 高并发下缓存失效问题
		① 缓存穿透
			A. 缓存穿透指查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，我们没有将这次查询的 null 写入缓存，
			这将导致不存在的数据每次请求都要到数据库去查询，失去了缓存的意义。
			B. 风险：利用不存在的数据进行攻击，数据库瞬间压力增大，最终导致崩溃
			C. 解决；null 结果缓存，并加入短暂的过期时间。
		② 缓存雪崩
			A. 缓存雪崩指的是在我们设置缓存时 key 采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到数据库查询，数据库瞬间压力过重
			雪崩
			B. 解决：原有的失效时间基础上增加一个随机值，比如 1-5 分钟随机，这样每个缓存的过期时间重复率就会降低，就很难引发集体失效的事件。
		③ 缓存击穿
			A. 对于一些设置了过期时间的 key，如果这些 key 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。
			B. 如果这个 key 在大量请求同时进来前正好失效，那么所有对这个key的数据查询都会落到数据库，称之为缓存击穿。
			C. 解决：加锁。大量并发只让一个人去查，其他人等待，查到以后释放锁，其他人获取到锁，先先查缓存，	就会有数据，不用查询数据库




























































