一、Nginx 内容概览
	1. nginx简介
		① 介绍nginx的应用场景和具体可以做什么事情
		② 介绍什么是反向代理
		③ 介绍什么是负载均衡
		④ 介绍什么是动静分离
	2. nginx安装
		① 介绍nginx在linux系统中如何进行安装
	3. nginx常用的命令和配置文件
		① 介绍nginx启动、关闭、重新加载命令
		② 介绍nginx的配置文件
	4. nginx配置实例-反向代理
	5. nginx配置实例-负载均衡
	6. nginx配置实例-动静分离
	7. nginx原理与优化参数配置
	8. 搭建nginx高可用集群
		① 搭建nginx高可用集群（主从模式）
		② 搭建 nginx 高可用集群（双主模式）
二、Nginx 简介
	1. Nginx概述
		Nginx ("engine x")是一个高性能的 HTTP 和反向代理服务器 特点是占有内存少，并发能力强，事实上 nginx 
		的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用 nginx 网站用户有：百度、京东、新浪、网易、
		腾讯、淘宝等
	2. Nginx 作为 web 服务器
		Nginx可以作为静态页面的 web 服务器，同时还支持 CGI 协议的动态语言，比如 perl 、 php等，但是不支持 java。 
		Java 程序只能通过与 tomcat 配合完成。 Nginx 专为性能优化而开发，性能是其最重要的考量，实现上非常注重效率，
		能经受高负载的考验 有报告表明能支持高达 50,000 个并发连接数。Tomcat 介绍参考https://lnmp.org/nginx.html
	3. 正向代理
		Nginx 不仅可以做反向代理，实现负载均衡。还能用作正向代理来进行上网等功能。正向代理：如果把局域网外的
		Internet 想象成一个巨大的资源库，则局域网中的客户端要访， 问 Internet，则需要通过代理服务器来访问，
		这种代理服务就称为正向代理。

								    正向代理
			用户访问局域网								局域网外的服务
			www.google.com  -----------x---------->     www.google.com
					↘										 ↗
					   ↘								  ↗
                          ↘						   ↗
                             ↘		代理服务器      ↗
	4. 反向代理
		反向代理，其实客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只需要将请求发送到反向代理服务器，
		由反向代理服务器去选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，
		暴露的是代理服务器地址，隐藏了真实服务器 IP 地址。

								    反向代理
			
												   ↗    192.168.107.27
		                                        ↗
										     ↗
		用户浏览器 ---------> www.123.com ----------->   192.168.107.8
											 ↘
												↘
												   ↘    192.168.107.30
    5. 负载均衡
		① 客户端发送多个请求到服务器，服务器处理请求，有一些可能要与数据库进行交互，服务器处理完毕后，再将结果返回给客户端。
		② 这种架构模式对于早期的系统相对单一，并发请求相对较少的情况下是比较适合的，成本也低。但是随着信息数量的不断增长，
		访问量和数据量的飞速增长，以及系统业务的复杂度增加，这种架构会造成服务器相应客户端的请求日益缓慢，并发量特别大的时候，
		还容易造成服务器直接崩溃。很明显这是由于服务器性能的瓶颈造成的问题，那么如何解决这种情况呢？
		③ 我们首先想到的可能是升级服务器的配置，比如提高CPU执行频率，加大内存等提高机器的物理性能来解决此问题，但是我们知道摩尔定律
		的日益失效，硬件的性能提升已经不能满足日益提升的需求了。最明显的一个例子，天猫双十一当天，某个热销商品的瞬时访问量是极其庞
		大的，那么类似上面的系统架构，将机器都增加到现有的顶级物理配置，都是不能够满足需求的。那么怎么办呢？
		④ 上面的分析我们去掉了增加服务器物理配置来解决问题的办法，也就是说纵向解决问题的办法行不通了，那么横向增加服务器的数量呢？这时
		候集群的概念产生了，单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情
		况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们所说的负载均衡
								    
									负载均衡
			
										请求分发   ↗    192.168.107.27
		                                        ↗
					发送请求			     ↗
		用户浏览器 ---------> www.123.com ----------->   192.168.107.8
											 ↘
												↘
												   ↘    192.168.107.30
	6. 动静分离
		为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。
								    
									动静分离
			
												   ↗    192.168.107.27
		                                        ↗        Tomcat（动态请求）
										     ↗
		用户浏览器 ---------> www.123.com ----------->   192.168.107.8
							 （nginx）|		 ↘           Tomcat（动态请求）
									  |			↘
									  ↓			   ↘    192.168.107.30
                            文件系统（所有静态资源）     Tomcat（动态请求）
三、Nginx 安装
	1. 下载 nginx 
		① 官网：http://nginx.org/
		② 需要的素材
			A. pcre
			B. openssl
			C. zlib
			D. nginx
	2. 安装 nginx
		① 第一步，安装 pcre
			A. 解压 pcre-8.37.tar.gz 到/usr/local/src/
			B. 执行./configure指令进行编译安装
			C. 编译完成之后使用 make && make install进行安装
		② 第二步，安装openssl
			A. 解压 openssl-1.1.1g.tar.gz 到/usr/local/src/
			B. 执行./config指令进行编译安装
			C. 编译完成之后使用 make && make install 指令进行安装
		③ 第三步，安装 zlib
			yum -y install zlib zlib-devel
		④ 第四步，安装 nginx
			A. 解压 nginx-1.12.2.tar.gz 到/usr/local/src/
			B. 执行./configure指令进行编译安装
			C. 编译完成之后使用 make && make install进行安装
四、nginx 常用的命令和配置文件
	1. nginx 常用的命令
		① 所有的命令均需在/usr/local/nginx/sbin/目录下进行
		② 启动命令：./nginx
			A. 启动nginx时可能出现以下的报错：
				error while loading shared libraries: libpcre.so.1: cannot open shared object file: No such file or directory
			B. 该问题的解决方法是建立以下软连接
				ln -s /usr/local/lib/libpcre.so.1 /lib64
		③ 关闭命令：./nginx -s stop
		④ 重新加载命令：./nginx -s reload
	2. nginx.conf 配置文件
		① nginx 安装目录下，其默认的配置文件都放在这个目录的 conf 目录下，而 主配置文件nginx.conf 也在其中，后续对 nginx 
		的使用基本上都是对此配置文件进行相应的修改配置
		② 配置文件中有很多 开头的表示注释内容，我们去掉所有以 # 开头的段落，精简之后的内容如下：
		worker_processes  1;

		events {
			worker_connections  1024;
		}

		http {
			include       mime.types;
			default_type  application/octet-stream;

			sendfile        on;
			
			keepalive_timeout  65;
			
			server {
				listen       80;
				server_name  localhost;

				location / {
					root   html;
					index  index.html index.htm;
				}

				error_page   500 502 503 504  /50x.html;
				location = /50x.html {
					root   html;
				}
			}
		}		

		③ 根据上述文件，我们可以很明显的将 nginx.conf 配置文件分为三部分：
			A. 全局块
				a. 从配置文件开始到 events 块之间的内容，主要会设置一些影响nginx 服务器整体运行的配置指令，主要包括配置运行 Nginx 
				服务器的用户（组）、允许生成的 worker process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。
				b. 比如上面第一行配置的：worker_processes  1; 这是 Nginx 服务器并发处理服务的关键配置，worker_processes 值越大，
				可以支持的并发处理量也越多，但是会受到硬件、软件等设备的制约
			B. events块
				a. 比如以下的配置：
					events {
						worker_connections  1024;
					}
				b. events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接，常用的设置包括是否开启对多 work process 下的网络连接进行序列化，
				是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 word process 可以同时支持的最大连接数等。 
				c. 上述例子就表示每个 work process 支持的最大连接数为 1024. 
				d. 这部分的配置对 Nginx 的性能影响较大，在实际中应该灵活配置。
			C. http块
				a. 这算是 Nginx 服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。 
				b. 需要注意的是：http 块也可以包括 http全局块、server 块。
					(1) http 全局块
						http全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。
					(2) server 块
						(A) 这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。
						(B) 每个 http 块可以包括多个 server 块，而每个 server 块就相当于一个虚拟主机。
						(C) 而每个 server 块也分为全局 server 块，以及可以同时包含多个 locaton 块。
							(a) 全局 server 块
								最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或IP配置。
							(b) location 块
								一个 server 块可以配置多个 location 块。
								这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称（也可以是IP别名）之外的字符串
								（例如 前面的 /uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。
五、nginx 配置实例-反向代理
	1. 反向代理实例一
		① 实现效果：使用 nginx 反向代理，访问 192.168.107.8 直接跳转到 192.168.107.8:8080，，出现Tomcat的主界面
		② 在 nginx.conf 配置文件中增加如下配置
			server {
				listen       80;
				server_name  192.168.107.8;

				location / {
					proxy_pass	http://127.0.0.1:8080
				}
			}
		③ 如上配置，我们监听80端口，访问域名为192.168.107.8，不加端口号时默认为80端口，故访问该域名时会跳转到127.0.0.1:8080路径上
	2. 反向代理实例二
		① 实现效果：使用 nginx 反向代理， 根据访问的路径跳转到不同端口的服务中，nginx 监听端口为 80
			A. 访问 http://192.168.107.8/yu/yu.html 直接跳转到 http://192.168.107.8:8080/yu/yu.html
			B. 访问 http://192.168.107.8/li/li.html 直接跳转到 http://192.168.107.27:8080/li/li.html
		② 实验代码
			A. 在两台主机上分别准备Tomcat，端口都是8080，并准备好测试的页面，即/yu/yu.html与/li/li.html
			B. 修改nginx的配置文件，在http块添加server{}
				server {
					listen       80;
					server_name  192.168.107.8;

					location ~ /yu/ {
						proxy_pass	http://127.0.0.1:8080;
					}
					
					location ~ /li/ {
						proxy_pass	http://192.168.107.27:8080;
					}
				}
		③ location 指令说明
			A. 该指令用于匹配 URL。
			B. 语法如下：
				location [ = | ~ | ~* | ^~] url {
				
				}
			C. 通配符说明
				a. =：用于不含正则表达式的 uri 前，要求请求字符串与 uri 严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求。
				b. ~：用于表示 uri 包含正则表达式，并且区分大小写。
				c. ~*：用于表示 uri 包含正则表达式，并且不区分大小写。
				d. ^~：用于不含正则表达式的 uri 前，要求 Nginx 服务器找到标识 uri 和请求字符串匹配度最高的 location 后，立即使用此 
				location 处理请求，而不再使用 location 块中的正则 uri 和请求字符串做匹配。
			D. 注意：如果 uri 包含正则表达式，则必须要有 ~ 或者 ~* 标识。
六、nginx 配置实例-负载均衡	
	1. 配置负载均衡	
		① 实现效果：配置负载均衡
		② 实验代码
			A. 在两台主机上分别准备Tomcat，端口都是8080，并准备好两个相同测试的页面
			B. 在 nginx.conf 中的http块中进行配置
				server {
					upstream myserver {
						server 192.168.107.8:8080;
						server 192.168.107.27:8080;
					}
					
					listen       80;
					server_name  192.168.107.8;

					location / {
						proxy_pass	http://myserver;
					}
					
				}
	2. 随着互联网信息的爆炸性增长，负载均衡（load balance ）已经不再是一个很陌生的话题顾名思义，负载均衡即是将负载分摊到不同的服务单元，
		既保证服务的可用性，又保证响应足够快，给用户很好的体验。快速增长的访问量和数据流量催生了各式各样的负载均衡产品，很多专业的负载均
		衡硬件提供了很好的功能，但却价格不菲，这使得负载均衡软件大受欢迎，nginx 就是其中的一个，在 linux 下有 Nginx 、 LVS 、 Haproxy 
		等等服务可以提供负载均衡服务，而且 Nginx 提供了几种分配方式 策略
		① 轮询（默认）
			每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
		② weight
			A. weight代表权 重默认为 1, 权重越高被分配的客户端越多
			B. 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 例如：
				upstream myserver {
					server 192.168.107.8:8080 weight=10;
					server 192.168.107.27:8080 weight=10;
				}
		③ ip_hash
			A. 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
			B. 举例：
				upstream myserver {
					ip_hash;
					server 192.168.107.8:8080;
					server 192.168.107.27:8080;
				}
		④ fair（第三方）
			A. 按后端服务器的响应时间来分配请求，响应时间短的优先分配。
			B. 举例
				upstream myserver {
					server 192.168.107.8:8080;
					server 192.168.107.27:8080;
					fair;
				}
七、nginx 配置实例 动静分离
	1. 动静分离简介：
		① Nginx 动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和静态页面物理分离。严格意义上说应该是动态请求跟静态请求分开，
		可以理解成使用Nginx 处理静态页面，Tomcat处理动态页面。动静分离从目前实现角度来讲大致分为两种，
		② 一种是纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案； 另外一种方法就是动态跟静态文件混合在一起发布，通过 nginx 来分开。
		③ 通过 location 指定不同的后缀名实现不同的请求转发。通过 expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。具体 Expires 定义：
		是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可，所以不会产生额外的流量。此种方法非常适合不经常变动的资源。
		（如果经常更新的文件，不建议使用 Expires 来缓存），我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，
		则不会从服务器抓取，返回状态码 304，如果有修改，则直接从服务器重新下载，返回状态码 200。
	2. 实验代码
		① 项目资源准备
			A. 在/home/目录下新建两个文件夹/home/views/ 和 /home/image/
			B. /home/views/用于放置HTML静态页面
			C. /home/image/用于放置图片
			D. 当用户访问http://192.168.107.8/views/时进入/home/views/文件目录，当访问http://192.168.107.8/image/时进入/home/image/目录
		② 在nginx.conf配置文件中的http块进行以下配置
			server {
				listen       80;
				server_name  192.168.107.8;

				location /views/ {
					root	/home/;
					autoindex	on;
				}
				
				location /image/ {
					root	/home/;
					autoindex	on;
				}
			}
		③ 添加监听端口、访问名字，重点是添加location
八、nginx 原理与优化参数配置	
	1. master & worker
											管理员
											  |
											 信号
											  |
	                    -------------------------------------------
	                    |   nginx             ↓                   |  
	                    |                 master进程              |
	                    |                  ↙ |  ↘               |
						|               ↙    |    ↘             |    
	                    |            信号   信号    信号          |
	                    |          ↙         |        ↘         |
	                    |        ↙            ↓           ↘       |
	                    | worker进程      worker进程   worker进程 |
						- -↗ ↖ ---------------↑------------↗ ↖-----
						 ↗    ↖             |          ↗    ↖
					  连接      连接         连接      连接     连接
					 ↗            ↖           ↑      ↗             ↖ 
				 Client            Client   Client Client           Client
	2. master-workers 的机制的好处
		首先，对于每个 worker 进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。
		其次，采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断， master 进程则很快启动新的
		worker 进程。当然， worker 进程的异常退出，肯定是程序有 bug 了，异常退出，会导致当前 worker 上的所有请求失败，
		不过不会影响到所有请求，所以降低了风险。
					client	 
					  |↖ ↖
					  |  ↖   ↖争抢
					  |    ↖   ↖
					  |      ↖    ↖
					  ↓         ↖     ↖
					master -------------- worker ----------> Tomcat
					↙     ↘      ↖            <----------
				  ↙          ↘      ↖
		 有新的“粮食”了          ↘       ↖
	                    监控管理   ↘  worker
	3. 需要设置多少个 worker
		Nginx同 redis 类似都采用了 io 多路复用机制，每个 worker 都是一个独立的进程，但每个进程里只有一个主线程，
		通过异步非阻塞的方式来处理请求， 即使是千上万个请求也不在话下。每个 worker 的线程可以把一个 cpu 的性能发挥到极致。
		所以 worker 数和服务器的 cpu数相等是最为适宜的。设少了会浪费 cpu ，设多了会造成 cpu 频繁切换上下文带来的损耗。
	4. 设置 worker 数量。
		① 在全局块中设置worker的数量worker_processes 4
		② work绑定 cpu (4 work 绑定 4cpu) 。
			worker_cpu_affinity 0001 0010 0100 1000
		③ work绑定 cpu (4 work 绑定 8cpu 中的 4 个 ) 。
			worker_cpu_affinity 0000001 00000010 00000100 00001000
	5. 连接数 worker_connection
	    这个值是表示每个worker 进程所能建立连接的最大值，所以，一个 nginx 能建立的最大连接数，应该是 worker_connections * worker_processes。
		当然，这里说的是最大连接数，对于HTTP 请求本地资源来说，能够支持的最大并发数量是 worker_connections *worker_processes ，
		如果是支持 http1.1 的浏览器每次访问要占两个连接，所以普通的静态访问最大并发数是： worker_connections * worker_processes /2 ，
		而如果是 HTTP 作为反向代理来说，最大并发数量应该是 worker_connections * worker_processes/4。因为作为反向代理服务器，每个并发会建立与
		客户端的连接和与后端服务的连接，会占用两个连接。
	6. nginx.conf的结构
		             work_progresses
		                  ↗
		               ↗
		            ↗
		nginx.conf ------------> events ---------> work_connection
	                ↘
	                   ↘
	                      ↘                 listen，server_name，……
	                        http           ↗
	                            ↘       ↗
	                               server -------> location -----> root，index
九、nginx 搭建高可用集群	
	1. Keepalived+Nginx 高可用集群 （主从模式）	
						 192.168.108.8					   192.168.108.8
						 Keepalived（主）----------------> Tomcat1
	                  ↗      ↑          ↘                ↗
				    ↗       |            ↘          ↗
	              ↗         |               ↘    ↗
		用户浏览器      192.168.107.44（虚拟IP）↘↗
	              ↘         |                ↗  ↘
	                ↘       |             ↗        ↘
	                  ↘      ↓          ↗               ↘  192.168.108.8
					    Keepalived（备）-----------------> Tomcat2                
	                    192.168.107.27
	2. 两台主机上分别安装 keepalived
		yum install keepalived -y
	3. 修改 /etc/keepalived/keepalived.conf
		global_defs { # 全局配置，除router_id，其余配置无太大的用处
			notification_email {
				acassen@firewall.loc
				failover@firewall.loc
				sysadmin@firewall.loc
			}
			notification_email_from Alexandre.Cassen@firewall.loc
			smtp_server 192.168.107.8
			smtp_connect_timeout 30
			router_id LVS_DEVEL # 访问的主机名
		}

		vrrp_script chk_http_port {
			script "/usr/local/src/nginx_check.sh"# 检测脚本文件
			interval 2 #（检测脚本执行的间隔）
			weight 2 # 表示权重，当脚本文件条件成立，即把当前主机的权重加减2
		}

		vrrp_instance VI_1 {
			state MASTER # 备份服务器上将 MASTER 改为 BACKUP
			interface eth0 # 网卡，使用ifconfig查看主机IP，主机IP前变量名即为网卡
			virtual_router_id 51 # 主、备机的 virtual_router_id 必须相同
			priority 100 # 主、备机取不同的优先级，主机值较大，备份机值较小
			advert_int 1 # 心跳，每秒向服务器发送一次请求
			authentication { #权限校验方式
				auth_type PASS
				auth_pass 1111
			}
			virtual_ipaddress {
				192.168.107.44 // VRRP H 虚拟地址
			}
		}
	4. 在/usr/local/src/目录下创建检测脚本文件nginx_check.sh
		#!/bin/bash
		A=`ps -C nginx -no-header |wc -l`
		if [ $A -eq 0 ];then
			/usr/local/nginx/sbin/nginx 
			sleep 2
			if [ `ps -C nginx --no-header |wc -l` eq 0 ];then
				killall keepalived
			fi
		fi
	5. 启动keepalived：service keepalived start
	6. 验证keepalived是否启动成功
		① 查看keepalived的进程：ps -ef|grep keepalived
		① 在浏览器上访问虚拟IP
		③ 使用ip a查看主机：可以发现主机上IP被虚拟IP代理
	6. 验证keepalived高可用性
		① 关闭192.168.107.8主机上的keepalived：service keepalived stop 
		② 关闭192.168.107.8主机上的nginx
		③ 继续在浏览器上访问虚拟IP
		④ 使用ip a查看备机：可以发现备机上IP被虚拟IP代理
	
	
	
	
	