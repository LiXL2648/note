一、消息队列
	1. MQ 的相关概念
		① 什么是 MQ
			MQ（Message Queue），从字面意思上看，本质是个队列，FIFO先进先出。只不过队列钟存放的内容是 Message 而已，还是一种跨进程的通信机制，
			用于上下游传递消息。在互联网架构中，MQ 是一种非常常见的上下游“逻辑解耦+物理解耦”的消息通信服务。使用 MQ 之后，消息发送只需要依赖
			MQ，不用依赖其他服务。
		② 为什么要用 MQ
			A. 流量消峰：
				举个例子，如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正常时段我们下一单一秒后就能
			返回结果。但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以
			取消这个限制，把一秒内下的订单分散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好。
			B. 应用解耦：
				以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合调用库存系统、物流系统、支付
			系统，任何一个子系统出了故障，都会造成下单操作异常。当转变成基于消息队列的方式后，系统间调用的问题就会减少很多，比如物流系统因为
			发生故障，需要几分钟来修复。在这几分钟的时间里，物流系统要处理的内存被缓存在消息队列中，用户的下单操作可以正常完成。当物流系统恢复
			后，继续处理订单信息即可，下单的过程中，用户感受不到物流系统的故障，提升系统的可用性。
			C. 异步处理
				有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可以执行完，以前一般有两种方式，A 过
			一段时间去调用 B 的 查询 API 查询。或者 A 提供一个 callback API，B 执行完之后调用 API 通知 A 服务。两种方式都不是很优雅，使用消息
			总线，可以很方便解决这个问题，A 调用 B 服务后，只需要监听 B 处理完的消息，当 B 处理完成后，会发送一条消息给 MQ，MQ 会将消息转发给
			A 服务。这样A 服务既不用循环调用 B 服务的查询 API，也不用提供 callback API。同样 B 服务也不用做这些操作。A 服务还能及时的得到异步
			处理成功的消息。
		③ MQ 的分类
			A. ActiveMQ
				a. 优点：单机吞吐万级，时效性 ms 级，基于主从架构实现高可用性，消息可靠性，较低的概率丢失数据
				b. 缺点：官方社区现在对 ActiveMQ 5，x 维护越来越少，高吞吐量场景较少使用。
			B. Kafka
				a. 大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开 Kafaka，这款为 大数据而生的消息中间件，以其百万计 TPS 的吞吐量名声大
				噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。目前已经被 LinkIn、Uber、Twitter、Netflix等
				大公司所采纳
				b. 优点：性能卓越，单机写入 TPS 约在百万条/秒，最大的优点，就是吞吐量高。时效性 ms 级可用性非常高。Kafka 是分布式，一个数据多
				个副本，少数机器宕机，不会丢失数据，不会导致不可用，消费者采用 Pull 方式获取消息，消息有序，通过控制能够保证所有消息被消费且仅
				被消费一次；有第三方 Kafka Web 管理界面 KafkaManager，在日志领域比较成熟，被多家公司合多个开源项目使用。功能支持：功能较为简单，
				主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用。
				c. 缺点：Kafka 单机超过 64 个队列/分区，Load 会发生明显的飙高现象，队列越多，load 越高，发送消息响应时间变长，使用短轮询方式，
				实时性取决于轮询间隔时间，消费失败不支持重试，支持消息顺序，但是一台代理宕机后，就会发送消息乱序，社区更新较慢。
			C. RocketMQ
				a. RocketMQ 出自阿里巴巴的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进。被阿里巴巴广泛应用在订单、
				交易、充值、流计算、消息推送、日志流式处理、binglog 分发等场景
				b. 优点：单机吞吐量十万级，可用性非常高，分布式架构，消息可以做到 0 丢失，MQ 功能较为完善，还是分布式的，扩展性好，支持 10 亿
				级别的消息堆积，不会因为堆积导致性能下降，源码是 Java，我们可以自己阅读源码，定制自己的 MQ
				c. 缺点：支持的客户端语言不多，目前是 Java 及 C++，其中 C++ 不成熟，社区活跃度一般，没有在 MQ 核心中去实现 JMS 等接口，有些系
				统要迁移需要修改大量代码
			D. RabbitMQ
				a. 2007年发布，是一个在 AMQP（高级消息队列协议）基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一
				b. 优点：由于 erlang 语言的高并发特性，性能较好；吞吐量达到万级，MQ 功能比较完备、健壮、稳定、易用、跨平台、支持多种语言，如：
				Python、Ruby、.NET、Java、JMS、C 、PHP、ActionScript、XMPP、STOMP等，支持 AJAX 文档齐全；开源提供管理界面非常棒，用起来很好用，
				社区活跃度高；更新频率相当高
				c. 商业版需要收费，学习成本较高
		④ MQ 的选择
			A. Kafka
				Kafka 主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是为了日志收集和传输，适合大量数据的互联网服务的数
			据收集业务。大型公司建议可以选用，如果有日志采集功能，肯定是首选 Kafka。
			B. RocketMQ
				天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务消峰，在大量交易涌入时，后端可能无法及时
			处理的情况。RocketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择
			RocketMQ。
			C. 	RabbitMQ
				结合 erlang 语言本身的并发优势，性能好时效微秒级，社区活跃度也比较高，管理界面用起来十分方便，如果数据量没有那么大，中小型公司
			优先选择功能比较完备的 RabbitMQ
	2. RabbitMQ
		① RabbitMQ 的概念
			RabbitMQ 是一个消息中间件：它接收并转发消息。可以把它当作一个快递点，当要发送一个包裹时，把包裹放在快递站，快递员最终会把快递送到收
			件人那里，按照这个逻辑 RabbitMQ 是一个快递站，一个快递员传递快件。RabbitMQ 与 快递站的主要区别在于，它不处理快件，而是接收，存储和转
			发消息数据
		② 四大核心概念
			A. 生产者：产生数据发送消息的程序是生产者
			B. 交换机：交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息推送到队列中。交换机必须确切知道它如
			何处理它接收到的消息，是将这些消息推送到特定的队列还是推送到多个队列，亦或是将消息丢弃，这个得有交换机类型决定
			C. 队列：队列是 RabbitMQ 内部使用得一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存储在队列中，队列仅受主机得内存和磁盘
			限制得约束，本质上是一个大得消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。这就是我们使用队列
			的方式。
			D. 消费者：消费者与接收者具有相似的含义，消费者大多时候是等待一个接收消息的程序，请注意生产者，消费者和消息中间件很多时候并不在同一
			个机器上，同一个应用程序既可以是生产者又可以是一个消费者。
		③ RabbitMQ 核心部分（六大模式）
			A. HelloWorld（简单模式）
			B. Work queues（工作模式）
			C. Publish/Subscribe（发布/订阅模式）
			D. Routing（路由模式）
			E. Topics（主题模式）
			F. Publish/Confirms（发布/确认模式）
		④ 各个名词介绍
			A. RabbitMQ 工作原理				
															
															+-----------------------------------+
															| 		Broker（RabbitMQ）			|
															|									|
									+-------------+			|						  +-------+ |		+-------------+
									| Connection  |			|					+---> | Queue |	|		| Connection  |
				+----------+		|   		  |			| +----------+		|	  +-------+	|		|   		  |		  +----------+
				| Producer | -----> | +---------+ | ------> | | Exchange | -----+				| ---->	| +---------+ | ----> | Consumer |
				+----------+		| | Channel | |			| +----------+		|	  +-------+	|		| | Channel | |		  +----------+
									| +---------+ |			|           		+---> | Queue |	|		| +---------+ |
									+-------------+			|						  +-------+	|		+-------------+
															+-----------------------------------+
			B. Broker：接收和分发消息的应用，RabbitMQ Server 就是 Message Broker
			C. Virtual host：出于多租户和安全因素设计，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同用户
			使用同一个 RabbitMQ Server 提供服务时，可划分出多个 vhost，每个用户在自己的 vhost 创建 exchange /queue。
			D. Connection：producer / consumer 和 Broker 之间的 Tcp 连接
			E. Channel：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销是巨大的，效率也低。Channel 是在 
			Connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个 Thread 创建单独的 Channel 进行通讯，AMQP method 包含了 Channel id 帮助
			客户端和 message broker 识别 Channel，所以 Channel 之间是完全隔离的。Channel 作为 轻量级的 Connection 极大减少了 操作系统建立 TCP 
			connection 的开销。
			F. Exchange：message 到达 Broker 的第一站，根据分发规则，匹配查询表中的 Routing key，分发到 queue 中去。常用的类型有：direct
			（point-to-point），Topic（publish/subscribe）and fanout（multicast）
			G. Queue：消息最终被送到 Queue 等待 Consumer 取走
			H. Binding：exchange 和 queue 之间的虚拟连接，bingding中可以包含 routing key，Bingding 信息被保存到 exchange 中的查询表中，用于 message 
			的分发依据。
		⑤ 安装
			A. 官网
				a. Rabbit 下载地址：https://www.rabbitmq.com/download.html
				b. Erlang 下载地址：https://www.erlang-solutions.com/downloads/#
			B. 文件上传：将文件上传到 /opt 目录
			C. 安装 Erlang
				a. 源码安装 
					(1) 选择安装erlang的文件夹，下载erlang
						cd /opt
						wget http://erlang.org/download/otp_src_24.0.tar.gz
					(2) 解压并进入到erlang目录
						tar -zxvf otp_src_24.0.tar.gz
						cd otp_src_24.0/
					(3) 配置
						./configure --prefix=/usr/local/erlang
					(4) 此时会再报“error: No curses library functions found”错，是因为没安装ncurses-devel，使用下面命令安装
						yum install -y ncurses-devel
					(5) 再次配置，此时会出现一堆信息，关注的是“APPLICATIONS DISABLED”内的区域，这里是我们缺少的组件，需要一个一个安装。看“APPLICATIONS 
					DISABLED”信息发现缺少oepnssl和odbc。
					(6) 安装opensll
						yum install -y openssl openssl-devel
					(7) 安装odbc
						yum -y install unixODBC-devel
					(8) 再配置，编译和安装
						./configure --prefix=/usr/local/erlang
						make && make install
					(9) 配置环境变量
						vi /etc/profile
						shift+g，输入以下内容
						export ERLANG_HOME=/usr/local/erlang
						export PATH=$PATH:$ERLANG_HOME/bin
						:wq!
						source /etc/profile
					(10) 验证是否安装成功
						erl -version
				b. rpm方式安装
					(1) 安装依赖项
						yum install -y epel-release
					(2) 下载rpm包
						wget https://packages.erlang-solutions.com/erlang/rpm/centos/7/x86_64/esl-erlang_24.0-1~centos~7_amd64.rpm
					(3) 安装erlang
						yum -y install esl-erlang_24.0-1~centos~7_amd64.rpm
					(4) 验证是否安装成功
						erl -version
			D. 安装 RabbitMQ
				a. 安装依赖项
					yum install socat -y
				b. 安装RabbitMQ
					rpm -ivh rabbitmq-server-3.8.22-1.el7.noarch.rpm
			E. 常用命令
				a. 添加开机启动 RabbitMQ 服务
					chkconfig rabbitmq-server on
				b. 启动服务
					/sbin/service rabbitmq-server start
				c. 查看服务状态
					/sbin/service rabbitmq-server status
				d. 关闭服务
					/sbin/service rabbitmq-server stop
			F. 开启 web 管理插件
				a. 关闭服务
					/sbin/service rabbitmq-server stop
				b. 开启 web 管理插件
					rabbitmq-plugins enable rabbitmq_management
				c. 启动服务
					/sbin/service rabbitmq-server start
				d. 用默认账号密码（guest）访问地址：10.10.0.26:15762
					User can only log in via localhost -- 没有权限
			G. 添加用户
				a. 创建账号
					rabbitmqctl add_user admin 2648
				b. 设置用户角色
					rabbitmqctl set_user_tags admin administrator
				c. 设置用户权限
					rabbitmqctl set_permissions [-p <vhostpath>] <user> <conf> <write> <read>
					rabbitmqctl set_permissions -p "/" admin ".*" ".*" ".*"
					用户 user_admin 具有 /vhost1 这个 virtual host 中所有资源的配置、写、读权限
				d. 当前用户和角色
					rabbitmqctl list_users
					user	tags
					admin	[administrator]
					guest	[administrator]
			H. 访问 RabbitMQ 的 web 界面：http://10.10.0.26:15672/
二、Hello World
		+---+		+-------+		+---+
		| P | ----> | 	|	| ----> | C |
		+---+		+-------+		+---+
	1. 创建工程
		① 创建父工程 rabbitmq
		② 创建模块 rabbitmq-hello
	2. 引入依赖
		<build>
			<plugins>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-compiler-plugin</artifactId>
					<configuration>
						<source>8</source>
						<target>8</target>
					</configuration>
				</plugin>
			</plugins>
		</build>

		<dependencies>
			<dependency>
				<groupId>com.rabbitmq</groupId>
				<artifactId>amqp-client</artifactId>
				<version>5.8.0</version>
			</dependency>

			<dependency>
				<groupId>commons-io</groupId>
				<artifactId>commons-io</artifactId>
				<version>2.6</version>
			</dependency>
		</dependencies>
	3. 生产者
		/**
		 * 生产者，发送消息
		 */
		public class Producer {

			private static final String QUEUE_NAME = "hello";

			public static void main(String[] args) throws Exception {

				// 创建一个连接工厂
				ConnectionFactory connectionFactory = new ConnectionFactory();
				// 设置连接 RabbitMQ 的 IP
				connectionFactory.setHost("10.10.0.26");
				// 设置用户名
				connectionFactory.setUsername("admin");
				// 设置密码
				connectionFactory.setPassword("2648");
				// 创建连接
				Connection connection = connectionFactory.newConnection();
				// 获取信道
				Channel channel = connection.createChannel();
				/*
				 * 声明一个队列
				 * queue: 队列名称
				 * durable：是否持久化
				 * exclusive：是否进行消息共享，true：多个消费者消费，false：单个消费者消费
				 * autoDelete：是否自动删除
				 * arguments：其他参数
				 */
				channel.queueDeclare(QUEUE_NAME, false, false, false, null);
				String message = "Hello World";
				/*
				 * 发送消息
				 * exchange：交换机
				 * routingKey：路由键，本次是队列名称
				 * props：其他参数
				 * body：消息
				 */
				channel.basicPublish("", QUEUE_NAME, null, message.getBytes());
				System.out.println("消息发送完毕");
			}
		}
	4. 消费者
		/**
		 * 消费者，接收消息
		 */
		public class Consumer {

			private static final String QUEUE_NAME = "hello";

			public static void main(String[] args) throws Exception {
				ConnectionFactory connectionFactory = new ConnectionFactory();
				connectionFactory.setHost("10.10.0.26");
				connectionFactory.setUsername("admin");
				connectionFactory.setPassword("2648");
				Connection connection = connectionFactory.newConnection();
				Channel channel = connection.createChannel();
				/*
				 * 消费者消费消息
				 * queue 队列名称
				 * autoAck 是否自动应答
				 * deliverCallback 消费者接收消息的回调
				 * cancelCallback 消费者取消消费的回调
				 */
				DeliverCallback deliverCallback = (consumerTag, message)-> {
					String msg = new String(message.getBody());
					System.out.println(msg);
				};

				CancelCallback cancelCallback = consumerTag -> {
					System.out.println("消息消费中断");
				};
				channel.basicConsume(QUEUE_NAME, true, deliverCallback, cancelCallback);
			}
		}
三、Work Queues
	1. 介绍：工作队列（又称任务队列）的主要思想是避免立即执行资源密集型任务，而不得不等待它完成。相反我们安排任务之后执行。我们把任务封装为消息并将
	其发送到队列。在后台运行的工作进程将弹出任务并最终执行作业。当有多个工作线程时，这些工作线程将一起处理这些任务。
										 +----+
								  +----> | C1 |
		+---+		+-------+	  |		 +----+
		| P | ----> | 	|	| ----+
		+---+		+-------+	  |		 +----+
								  +----> | C2 |
										 +----+
	2. 轮询分发消息：在这个案例中将会启动两个工作线程，一个消息发送线程，看看两个工作线程是如何工作的。
		① 任务
			public class Task {

				private static final String QUEUE_NAME = "hello";

				public static void main(String[] args) throws Exception {
					Channel channel = RabbitMQUtil.getChannel();

					channel.queueDeclare(QUEUE_NAME, false, false, false, null);
					Scanner scanner = new Scanner(System.in);
					while (scanner.hasNext()) {
						String message = scanner.next();
						channel.basicPublish("", QUEUE_NAME, null, message.getBytes());
						System.out.println("发送消息：" + message);
					}
				}
			}
		② 工作线程
			public class Worker {

				private static final String QUEUE_NAME = "hello";

				public static void main(String[] args) throws Exception {
					Channel channel = RabbitMQUtil.getChannel();

					DeliverCallback deliverCallback = (consumerTag, message) -> {
						String msg = new String(message.getBody());
						System.out.println("接收到的消息：" + msg);
					};
					CancelCallback cancelCallback =  consumerTag -> System.out.println("消息消费中断");
					System.out.println("Worker02 等待接收消息");
					channel.basicConsume(QUEUE_NAME, true, deliverCallback, cancelCallback);
				}
			}
		③ 工具类
			public class RabbitMQUtil {

				public static Channel getChannel() throws Exception {
					// 创建一个连接工厂
					ConnectionFactory connectionFactory = new ConnectionFactory();
					// 设置连接 RabbitMQ 的 IP
					connectionFactory.setHost("10.10.0.26");
					// 设置用户名
					connectionFactory.setUsername("admin");
					// 设置密码
					connectionFactory.setPassword("2648");
					// 创建连接
					Connection connection = connectionFactory.newConnection();
					// 获取信道
					return connection.createChannel();
				}
			}
	3. 消息应答
		① 概念：消费者完成一个任务可能需要一段时间，如果其中一个消费者处理一个长任务并仅只完成了部分突然就挂了。RabbitMQ一旦向消费者传递了一条消息，便立
		即将该消息标记为删除。在这个情况下，突然有个消费者挂掉了，正在处理的消息将会丢失。为了保证消息在发送过程中不会丢失，rabbitmq引入消息应答机制，消
		息应答就是：消费者在接收到消息并处理该消息之后，告诉RabbitMQ它已经处理了，rabbitMQ可以把该消息删除了。
		② 自动应答：消息发送后立即被认为已经传送成功，这种模式需要在高吞吐量和数据传输安全性方面做权衡，因为这种模式如果消息在接收之前，消费者那边出现连接
		或者channel关闭，那么消息就丢失了，当然另一方面这种模式消费者可以传递过载地消息，没有对传递的消息数量进行限制，当然这样有可能使得消费者这边由于接收
		太多还来不及处理的消息，导致这些消息的积压，最终使得内存耗尽，最终这些消费者线程被操作系统杀死，所以这种模式仅适用在消费者可以高效并以某种速率能够
		处理这些消息的情况下使用。
		③ 手动应答，消息应答的方法
			A. Channel.basicAck()：用于肯定确认，RabbitMQ已经知道消息被接收并且被成功处理，可以将其丢弃了
			B. Channel.basicNack()：用于否达确认
			C. Channel.basicReject()：用于否定确认，不处理该消息了直接拒绝，可以将其丢弃了，与Channel.basicNack()相比少了一个参数 multiple。
		④ multiple的解释，手动应答的好处是可以批量应答并且减少网络拥堵
			A. multiple 的 true 和 false 代表不同意思
			B. true：代表批量应答 channel 上未应答的消息，比如说channel上有传送 tag 的消息 5、6、7、8，当前 tag 是 8，那么此时 5-8 的这些还未应答的消息都会
			被确认收到消息应答
			C. false：同上面相比，只会应答 tag=8 的消息，5、6、7这三个消息依然不会被确认收到消息应该
		⑤ 消息自动重新入队：如果消费者由于某些原因失去连接（其通道已关闭，连接已关闭或者 TCP  连接丢失），导致消息未发送 ACK 确认，RabbitMQ 将了解到消息未
		完全处理，并将其重新排队。如果此时其他消费者可以处理，它很快将其重新分发给另一个消费者。这样，即某个消费者偶尔死亡，也可以确保不会丢失任何消息。
		⑥ 消息手动应答代码
			A. 默认消息采用的是自动应答，所以我们要想实现消息消费过程中不丢失，需要把自动应答改为手动应答。	
			B. 生产者
				public class Producer {

					private static final String QUEUE_NAME = "hello";

					public static void main(String[] args) throws Exception {

						Channel channel = RabbitMQUtil.getChannel();

						channel.queueDeclare(QUEUE_NAME, false, false, false, null);
						Scanner scanner = new Scanner(System.in);
						while (scanner.hasNext()) {
							String message = scanner.next();
							channel.basicPublish("", QUEUE_NAME, null, message.getBytes());
							System.out.println("生产者发送消息：" + message);
						}
					}
				}
			C. 消费者1
				public class Consumer1 {

					private static final String QUEUE_NAME = "hello";

					public static void main(String[] args) throws Exception {

						Channel channel = RabbitMQUtil.getChannel();
						System.out.println("C1 等待接收消息，处理消息时间较短");
						DeliverCallback deliverCallback = (consumerTag, message) -> {
							// 睡眠1秒钟
							try {
								Thread.sleep(1000);
							} catch (InterruptedException ignored) {}
							System.out.println("C1接收消息：" + new String(message.getBody()));
							// 手动应答
							/*
							 * deliveryTag：消息标记
							 * multiple：是否批量应答，一般是不批量，即处理一条应答一次
							 */
							channel.basicAck(message.getEnvelope().getDeliveryTag(), false);
						};

						CancelCallback cancelCallback = consumerTag -> System.out.println("C1消息接收中断");
						channel.basicConsume(QUEUE_NAME, false, deliverCallback, cancelCallback);
					}
				}
			D. 消费者2
				public class Consumer2 {

					private static final String QUEUE_NAME = "hello";

					public static void main(String[] args) throws Exception {

						Channel channel = RabbitMQUtil.getChannel();
						System.out.println("C2 等待接收消息，处理消息时间较长");
						DeliverCallback deliverCallback = (consumerTag, message) -> {
							// 睡眠1秒钟
							try {
								Thread.sleep(30000);
							} catch (InterruptedException ignored) {}
							System.out.println("C2接收消息：" + new String(message.getBody()));
							// 手动应答
							/*
							 * deliveryTag：消息标记
							 * multiple：是否批量应答，一般是不批量，即处理一条应答一次
							 */
							channel.basicAck(message.getEnvelope().getDeliveryTag(), false);
						};

						CancelCallback cancelCallback = consumerTag -> System.out.println("C1消息接收中断");
						channel.basicConsume(QUEUE_NAME, false, deliverCallback, cancelCallback);
					}
				}
			E. 测试：首先生产者发送消息 AA 和 BB，等待 C1 和 C2 消费，C1 成功消费，由于 C2 处理消息时间较久，三十秒后 C2 才处理完消息。接着生产者发送消息 CC 和 DD，
			C1 成功消费，断开 C2，此时消息 DD 没有被应答而从新入队，被 C1 成功消费
	4. RabbitMQ 持久化
		① 概念：保障当 RabbitMQ 服务停掉以后消息生产者发送过来的消息不丢失。默认情况下 RabbitMQ 退出或由于某种原因奔溃时，它忽视队列和消息，除非告知它不要这样做。
		确保消息不丢失需要做两件事：我们需要将队列和消息都标记为持久化。
		② 队列如何实现持久化
			A. 之前我们创建的队列都是非持久化的，rabbitmq 如果重启，该队列就会被删除掉，如果队列要实现持久化，需要在声明队列的时候把 durable 参数设置为持久化
				channel.queueDeclare(QUEUE_NAME, true, false, false, null);
			B. 但是需要注意的是如果之前声明的队列不是持久化的，需要把原先队列先删除，不然会报错
		③ 消息实现持久化
			A. 要想让消息实现持久化需要在消息生产者修改发布消息的代码，添加属性：MessageProperties.PERSISTENT_TEXT_PLAIN
				channel.basicPublish("", QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes());
			B. 将消息标记为持久化并不能完全保证不会丢失消息。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是这里依然存在当消息刚准备存储在磁盘的时候，但是还没有完全存储完，
			消息还在缓存的一个间隔点。此时并没有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，已经绰绰有余了。
	5. 不公平分发
		① 在最开始的时候我们学习到 RabbitMQ 分发消息采用的轮询分发，但是在某种场景下这种策略并不是很好，比方说有两个消费者在处理任务，其中消费者1处理消息速度非常快，
		而消费者2处理速度却很慢，这个时候我们还是采用轮询分发的话，这个处理速度快的消费者会处于空闲状态，而处理慢的那个消费者一直在干活，这种分配方式在这种情况下其实
		不是很友好，但是 RabbitMQ 并不知道这种情况，它依然很公平地进行分发
		② 为了避免这种情况，在消费方未接收消息时设置参数 channel.basicQos(1)，1：代表不公平分发；0：轮询分发，> 1：预取值
			channel.basicQos(1);
		③ 意思就是如果这个任务还没完成或者没有应答，则先不分配，然后 RabbitMQ 就会把任务分配给没有那么忙的那个空闲消费者，当然如果所有消费者都没有完成手上任务，队列还在
		不停添加新的任务，队列有可能就会遇到被撑满的情况，这个时候就只能添加新的 worker 或者改变其他存储任务的策略
	6. 预取值
		① 本身消息的发送就是异步发送的，所有在任何时候，channel 上肯定不止只有一个消息，另外消费者的手动确认本质上也是异步的。因此这里就存在一个未确认的消息缓冲区。因此
		希望开发人员能限制此缓冲区的大小，以避免缓冲区里面无限制的未确认消息问题。这个时候就可以通过使用basic.qos方法设置“预取计数”值来完成。该值定义通道上允许的未确认消
		息的最大数量。一旦数量达到配置的数量，RabbitMQ 将停止在信道上传递更多消息，除非至少有一个未处理的消息被确认，例如：假设在通道上有未确认的消息5、6、7、8，并且通道
		的预取计数设置为4，此时 RabbitMQ 将不会在该通道上再传递任何消息，除非至少有一个未应答的消息被 ack。比方说 tag = 6 这个消息刚刚被确认 ack，RabbitMQ 将会感知这个情
		况并再发送一条消息。虽然自动应答传输消息速率是最佳的，但是，在这种情况下已传递但尚未处理的消息的数量也会增加，从而增加了消费者的RAM消耗（随机存取存储器），应该小
		心使用具有无限预处理的自动确认模式或者手动确认模式，消费者消费了大量的消息如果没有确认的话，会导致消费者连接节点的内存消耗变大，所以找到合适的预取值是一个反复试验
		的过程，不同的负载改值也不同，从 100 到 300 范围内的值通常可提供最佳的吞吐量，并且不会给消费者带来太大的风险。预取值为1是最保险的，当然这将使吞吐量变得很低，特别
		是在消费连接等待时间较长的环境中，对于大多数应用来说，稍微高一点的值将是最佳的
四、发布确认
	1. 发布确认原理
		① 生产者将信道设置成 confirm 模式，一旦信道进入 confirm 模式，所有在该信道上面发布的消息都会被指派一个唯一的ID（从1开始），一旦消息被投递到所有	匹配的队列之后，
		broker就会发送一个确认给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘后发出，
		broker 回传给生产者的确认消息中 delivery-tag 域包含了确认消息的序列号，此外 broker 也可以设置basic.ack的 multiple 域，表示到这个序列号之前的所有消息都已经得到处理。
		② confirm 模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通
		过回调方法来处理该确认消息，生产者应用程序同样可以在回调方法中处理该 nack 消息
	2. 发布确认的策略
		① 开启发布确认的方法：发布确认默认是没有开启的，如果需要开启需要调用channel.confirmSelect，每当想要使用发布确认，都需要在channel上调用该方法
			
		② 单个确认发布
			A. 这是一种简单的确认方式，它是一种同步确认发布的方式，也就是发布一个消息之后只有它被确认发布，后续的消息才能继续发布，waitForConfirmOrDie(long) 这个方法自有在
			消息被确认的时候才返回，如果在指定时间范围内这个消息没有被确认那么它将抛出异常
			B. 这种确认方式有一个最大的缺点就是：发布速度特别慢，因为如果没有确认发布的消息就会阻塞所有后续消息的发布。这种方式最多提供每秒不超过数百条发布消息的吞吐量。当
			然对于某些应用程序来说这可能已经足够了。
			C. 单个发布确认代码
				public static void singleConfirm() throws Exception {
					Channel channel = RabbitMQUtil.getChannel();
					// 发布确认
					channel.confirmSelect();
					// 声明队列为持久化
					channel.queueDeclare(QUEUE_NAME, true, false, false, null);
					long start = System.currentTimeMillis();
					for (int i = 0; i < MESSAGE_COUNT; i++) {
						String message = i + "";
						channel.basicPublish("", QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes());
						boolean confirms = channel.waitForConfirms();
						System.out.println(confirms ? "发送成功" : "发送失败");
					}
					long end = System.currentTimeMillis();
					System.out.println("发布" + MESSAGE_COUNT + "个单独确认消息，耗时：" + (end- start) + "ms");
				}
		③ 批量确认发布
			A. 上面那种方式非常慢，与单个等待确认相比，先发布一批消息后一起确认可以极大地提高吞吐量，当然这种方式地缺点就是：当发送故障导致发布出现问题时，不知道是哪个消息
			出现问题了，我们必须将整个批处理保存到内存中，以记录重要的信息而后重新发布消息。当然这种方案仍然是同步的，也一样阻塞消息的发布
			B. 批量发布确认代码
				public static void multipleConfirm() throws Exception {
					Channel channel = RabbitMQUtil.getChannel();
					// 发布确认
					channel.confirmSelect();
					// 声明队列为持久化
					channel.queueDeclare(QUEUE_NAME, true, false, false, null);
					long start = System.currentTimeMillis();

					int batchSize = 100;
					for (int i = 1; i <= MESSAGE_COUNT; i++) {
						String message = i + "";
						channel.basicPublish("", QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes());
						if (i % batchSize == 0) {
							channel.waitForConfirms();
						}
					}
					long end = System.currentTimeMillis();
					System.out.println("发布" + MESSAGE_COUNT + "个批量确认消息，耗时：" + (end- start) + "ms");
				}
		④ 异步发布确认
			A. 异步确认虽然编程逻辑比上两个要复杂，但是性价比最高，无论是可靠性还是效率都没得说，他是利用回调函数来达到消息可靠性传递的，这个中间件也是通过函数回调来保证是否
			投递成功。
			B. 异步发布确认代码
				public static void asyncConfirm() throws Exception {
					Channel channel = RabbitMQUtil.getChannel();
					// 发布确认
					channel.confirmSelect();
					// 声明队列为持久化
					channel.queueDeclare(QUEUE_NAME, true, false, false, null);
					long start = System.currentTimeMillis();

					/*
					 * deliveryTag：消息标记
					 * multiple：是否批量
					 */
					// 消息确认成功回调函数
					ConfirmCallback ackCallback = (deliveryTag, multiple) -> {
						System.out.println("确认的消息：" + deliveryTag);
					};
					// 消息确认失败回调函数
					ConfirmCallback nackCallback = (deliveryTag, multiple) -> {
						System.out.println("未确认的消息：" + deliveryTag);
					};;

					// 准备监听器，监听哪些消息成功，哪些消除失败，异步
					channel.addConfirmListener(ackCallback, nackCallback);
					for (int i = 0; i < MESSAGE_COUNT; i++) {
						String message = i + "";
						channel.basicPublish("", QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes());
					}

					long end = System.currentTimeMillis();
					System.out.println("发布" + MESSAGE_COUNT + "个异步确认消息，耗时：" + (end- start) + "ms");
				}
		⑤ 如何处理异步未确认消息：
			A. 最好的解决方案就是把未确认的消息放到一个基于内存的能够被发布线程访问的队列，比如用 ConcurrentLinkedQueue 这个队列在 confirm callback 与发布线程之间进行消息的传递
			B. 处理异步未确认消息代码
				public static void asyncConfirm() throws Exception {
					Channel channel = RabbitMQUtil.getChannel();
					// 发布确认
					channel.confirmSelect();
					// 声明队列为持久化
					channel.queueDeclare(QUEUE_NAME, true, false, false, null);
					/*
					 * 线程安全有序的哈希表，适用于高并发的情况下
					 * 将序号与消息关联
					 * 批量删除消息
					 * 支持高并发（多线程）
					 */
					ConcurrentSkipListMap<Long, String> outStandingConfirms = new ConcurrentSkipListMap<>();

					/*
					 * deliveryTag：消息标记
					 * multiple：是否批量
					 */
					// 消息确认成功回调函数
					ConfirmCallback ackCallback = (deliveryTag, multiple) -> {
						System.out.println("确认的消息：" + deliveryTag);
						// 删除确认的消息，剩下的就是未确认的消息
						if (multiple) {
							ConcurrentNavigableMap<Long, String> confirmed = outStandingConfirms.headMap(deliveryTag);
							confirmed.clear();
						} else {
							outStandingConfirms.remove(deliveryTag);
						}
					};
					// 消息确认失败回调函数
					ConfirmCallback nackCallback = (deliveryTag, multiple) -> {
						String message = outStandingConfirms.get(deliveryTag);
						System.out.println("未确认的消息：" + deliveryTag + ", " + message);
					};;

					// 准备监听器，监听哪些消息成功，哪些消除失败，异步
					channel.addConfirmListener(ackCallback, nackCallback);
					long start = System.currentTimeMillis();
					for (int i = 0; i < MESSAGE_COUNT; i++) {
						String message = i + "";
						channel.basicPublish("", QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes());
						// 记录发送的消息
						outStandingConfirms.put(channel.getNextPublishSeqNo() - 1 , message);
					}

					long end = System.currentTimeMillis();
					System.out.println("发布" + MESSAGE_COUNT + "个异步确认消息，耗时：" + (end- start) + "ms");
				}
		⑥ 三种发布确认速度对比
			A. 单独发布消息：同步等待，简单，但吞吐量非常有限
			B. 批量发布消息：批量同步等待确认，简单，合理的吞吐量，一旦出现问题很难推断是哪条消息出现了问题
			C. 异步处理：最佳性能和资源使用，在出现错误的情况下可以很好地控制，但实现起来稍微有难度
五、交换机
	1. Exchanges
		① Exchanges 概念
			A. RabbitMQ 消息传递模型的核心思想是：生产者生产的消息从不会直接发送到队列。实际上，通常生产者甚至不知道这些消息传递到哪些队列中
			B. 相反，生产者只能将消息发送到交换机（Exchange），交换机工作内容非常简单，一方面它接收来自生产者的消息，另一方面将它们推入队列。交换机必须确切知道如何处理收到的
			消息。是应该把这些消息放到特定队列还是说把他们放多多个队列，或者是丢弃。这些由交换机的类型来决定。
		② Exchanges 的类型：
			A. 接（direct）
			B. 主题（topic）
			C. 标题（headers）
			D. 扇出（fanout）
		③ 无名 Exchange
			A. 在本教程的前面部分对 Exchange 一无所知，但仍然能够将消息发送到队列。之前能实现的原因是因为我们使用的是默认交换机，我们通过空字符串进行标识
				channel.basicPublish("", QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes());
			B. 第一个参数就是交换机的名称。空字符表示默认或者无名交换机；消息能路由发送到队列中其实是由 routeKey（bingKey）绑定 key 指定的，如果它存在的话
	2. 临时队列
		① 每当我们连接到 RabbitMQ 时，我们都需要一个全新的空队列，为此我们可以创建一个具有随即名称的队列，或者能让服务器为我们选择一个随机队列名称。其次一旦断开消费者的连接，
		队列将自动删除
		② 创建临时队列的方式如下
			String queueName = channel.queueDeclare().getQueue()
	3. 绑定（bindings）：其实是 交换机（Exchange） 和 队列（queue）之间的桥梁，它告诉我们 exchange 和哪个队列进行了绑定关系
	4. Fanout（扇出，发布/订阅）
		① Fanout介绍：Fanout这种类型非常简单。从名称中猜出，它是将接收到的所有消息广播到它知道的所有队列中。系统中默认由 Fanout 类型的交换机
								binding    +------+
						logs	  	+----> |   Q1 | ReceiveLogs1
			+---+		+---+	  	|	   +------+
			| P | ----> | X | ------+
			+---+		+---+	  	|	   +------+
									+----> |   Q2 | ReceiveLogs2
								binding    +------+
					type:fanout
		② 接收者
			public class ReceiveLogs1 {

				private static final String EXCHANGE_NAME = "logs";

				public static void main(String[] args) throws Exception {
					Channel channel = RabbitMQUtil.getChannel();

					/*
					 * 声明交换机
					 * exchange：交换机名称
					 * type：交换机类型
					 */
					channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT);
					// 声明临时队列，当消费者与队列断开连接时自动删除队列
					String queue = channel.queueDeclare().getQueue();
					/*
					 * 交换机绑定队列
					 * queue：队列名称
					 * exchange：交换机名称
					 * routingKey：路由键
					 */
					channel.queueBind(queue, EXCHANGE_NAME, "");
					System.out.println("ReceiveLogs1 等待接收消息……");
					DeliverCallback deliverCallback = (consumerTag, message) -> {
						System.out.println("ReceiveLogs1 接收到的消息："+ new String(message.getBody()));
					};
					channel.basicConsume(queue, true, deliverCallback, consumerTag ->{});
				}
			}
		③ 生产者
			public class EmitLog {

				private static final String EXCHANGE_NAME = "logs";

				public static void main(String[] args) throws Exception {

					Channel channel = RabbitMQUtil.getChannel();
					channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT);

					Scanner scanner = new Scanner(System.in);
					while (scanner.hasNext()) {
						String message = scanner.next();
						channel.basicPublish(EXCHANGE_NAME, "", false, null, message.getBytes());
						System.out.println("生产者发送消息：" + message);
					}
				}
			}
	5. Direct Exchange（直接交换机）
		① 回顾
			A. 在上一点中，构建了一个简单的日志记录系统，能够向许多接收者广播日志消息。而如果向其中添加一些特别的功能，比方说只让某个消费者订阅发布的部分消息。例如只把
			严重错误消息定向存储到日志文件（以节省磁盘空间）。同时仍然能够在控制台商打印所有日志消息
			B. 再次回顾 bindings，绑定是交换机和队列之间的桥梁关系。也可以这么理解：队列只对它绑定交换机消息感兴趣。绑定参数：routingKey 来表示也可称参数为 bindingKey，创建
			绑定代码：hannel.queueBind(queue, EXCHANGE_NAME, "routingKey")，绑定之后的意义由其交换类型决定
		② Direct Exchange 介绍
			A. 上点：日志系统将所有消息广播给所有消费者，对此做一些改变，例如希望将日志消息写入磁盘的程序仅接收严重错误（errors），而不存储警告（warning）或者信息（info）日
			志消息避免浪费磁盘空间。Fanout 这种交换类型并不能给我们带来很大的灵活性，它只能进行无意识的广播，在这里将使用 direct 这种类型进行替换，这种类型的工作方式是：消息
			只去到它绑定的 routingKey队列中去。
			
										orange   +----+		  +----+
									  +--------> | Q1 | ----> | C1 |
						type=direct	  | 		 +----+		  +----+
				+---+		+---+	  |	black	 +----+		  +----+
				| P | ----> | X | ----+--------> | Q2 | ----> | C2 |
				+---+		+---+	  |			 +----+		  +----+
									  |	green	   ↑
									  +------------+
									  | blue
									  +--------> 没有绑定关系，直接丢弃
									  
			B. 在这上面这张图中，可以看到 X 绑定了两个队列，绑定类型是 direct。队列 Q1 绑定的 routingKey 为 orange，队列 Q2 绑定的 routingKey 有两个：一个绑定键为 black，另一个
			绑定键为green
			C. 在 这种绑定情况下，生产者发布消息到 exchange 上，绑定键为 orange 的消息会发布到队列 Q1，绑定键 black 和 green 的消息会被发布到队列 Q2，其他类型的消息将被丢弃。
		③ 多重绑定，如果 exchange 的绑定类型是 direct，但是它绑定的多个队列的 key 如果都相同，在这种情况下虽然绑定类型是 direct，但是它表现的就和 fanout 有点类似。		
			
										black    +----+		  +----+
									  |--------> | Q1 | ----> | C1 |
						type=direct	  | 		 +----+		  +----+
				+---+		+---+	  |	black	 +----+		  +----+
				| P | ----> | X | ----|--------> | Q2 | ----> | C2 |
				+---+		+---+	  			 +----+		  +----+
	6. Topic（主题交换机）
		① 之前类型的问题
			A. 在上一点，改进了日志系统，没有使用只能进行随意广播的 fanout 交换机，而是使用了 direct 交换机，从而实现有选择性地接收日志
			B. 尽管使用了 direct 交换机改进了系统，但是它仍然存在局限性，比方接收的日志类型有 info.base 和 info.advantage，某个队列只想 info.base 的消息，那这个时候 direct 就办
			不到了。也就是说 direct 只能将消息发送到一个队列，无法同时发送到多个队列中。
			这个时候只能使用 topic 类型
		② topic 的要求
			A. 发送到类型是 topic 交换机的消息的 routingKey 不能随意写，必须满足一定的要求，它必须是一个单词列表，以点号分隔开，这些单词可以是任意单词，比如说："stock.usd.nyse"，
			"nyse.vmw"，"quick.orange.rabbit" 这种类型的，当然这个单词列表最多不能超过 255 个字节。
			B. 在这个规则列表中，其中有两个替换符
				a. *(星号)可以代替一个单词
				b. #(井号)可以替代零个或多个单词
		③ Topic 匹配案例 
			A. 下图绑定关系如下
				a. Q1-->绑定的是中间带 orange 带 3 个单词的字符串(*.orange.*)
				b. Q2-->绑定的是最后一个单词是 rabbit 的 3 个单词(*.*.rabbit)，第一个单词是 lazy 的多个单词(lazy.#)
													
										  *.orange.* +-------+		 +----+
							type=topic	  +--------> |	 Q1	 | ----> | C1 |
					+---+		+---+	  |			 +-------+		 +----+
					| P | ----> | X | ----+
					+---+		+---+	  |*.*.rabbit+-------+		 +----+
										  +--------> |   Q2  | ----> | C2 |
										  |			 +-------+		 +----+
										  |lazy.#		 ↑
										  +--------------+
			B. 上图是一个队列绑定关系图，我们来看看他们之间数据接收情况是怎么样的
				a. quick.orange.fox：被队列 Q1 接收到
				b. lazy.brown.fox：被队列 Q2 接收到
				c. lazy.pink.rabbit：虽然满足两个绑定但只被队列 Q2 接收一次
				d. quick.brown.fox：不匹配任何绑定不会被任何队列接收到会被丢弃
				e. quick.orange.male.rabbit：是四个单词不匹配任何绑定会被丢弃
				f. lazy.orange.male.rabbit：是四个单词但匹配 Q2
			C. 当队列绑定关系是下列这种情况时需要引起注意
				a. 当一个队列绑定键是 #,那么这个队列将接收所有数据，就有点像 fanout 了
				b. 如果队列绑定键当中没有 # 和 * 出现，那么该队列绑定类型就是 direct 了
		④ 实战
			A. 消费者1
				public class ReceiveLogsTopic1 {

					private static final String EXCHANGE_NAME = "topic_logs";

					public static void main(String[] args) throws Exception {

						Channel channel = RabbitMQUtil.getChannel();

						channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC);
						String queue = "Q1";
						channel.queueDeclare(queue, false, false, false, null);
						channel.queueBind(queue, EXCHANGE_NAME, "*.orange.*");
						DeliverCallback deliverCallback = (consumerTag, message) -> {
							System.out.println("ReceiveLogsTopic1 接收消息：" + new String(message.getBody()));
						};
						System.out.println("ReceiveLogsTopic1 准备接收消息……");
						channel.basicConsume(queue, true, deliverCallback, consumerTag -> {});
					}
				}
			B. 消费者2
				public class ReceiveLogsTopic2 {

					private static final String EXCHANGE_NAME = "topic_logs";

					public static void main(String[] args) throws Exception {

						Channel channel = RabbitMQUtil.getChannel();

						channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC);
						String queue = "Q2";
						channel.queueDeclare(queue, false, false, false, null);
						channel.queueBind(queue, EXCHANGE_NAME, "*.*.rabbit");
						channel.queueBind(queue, EXCHANGE_NAME, "lazy.#");
						DeliverCallback deliverCallback = (consumerTag, message) -> {
							System.out.println("ReceiveLogsTopic2 接收消息：" + new String(message.getBody()));
						};
						System.out.println("ReceiveLogsTopic2 准备接收消息……");
						channel.basicConsume(queue, true, deliverCallback, consumerTag -> {});
					}
				}
			C. 生产者
				public class TopicLogs {

					private static final String EXCHANGE_NAME = "topic_logs";

					public static void main(String[] args) throws Exception {

						Channel channel = RabbitMQUtil.getChannel();

						channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC);
						Map<String, String> bindingKeyMap = new LinkedHashMap<>();
						bindingKeyMap.put("quick.orange.rabbit", "被队列 Q1Q2 接收到");
						bindingKeyMap.put("lazy.orange.elephant", "被队列 Q1Q2 接收到");
						bindingKeyMap.put("quick.orange.fox", "被队列 Q1 接收到");
						bindingKeyMap.put("lazy.brown.fox", "被队列 Q2 接收到");
						bindingKeyMap.put("lazy.pink.rabbit", "虽然满足两个绑定但只被队列 Q2 接收一次");
						bindingKeyMap.put("quick.brown.fox", "不匹配任何绑定不会被任何队列接收到会被丢弃");
						bindingKeyMap.put("quick.orange.male.rabbit", "是四个单词不匹配任何绑定会被丢弃");
						bindingKeyMap.put("lazy.orange.male.rabbit", "是四个单词但匹配 Q2");
						bindingKeyMap.forEach((k, v) -> {
							try {
								channel.basicPublish(EXCHANGE_NAME, k, null, v.getBytes());
							} catch (IOException ignored) {}
						});
					}
				}
六、死信队列
	1. 死信的概念
		① 先从概念上解释上搞清这个定义，死信，顾名思义就是无法被消费的消息，字面上意思可以这样理解，一般来说。producer 将消息投递到broker或者直接到queue里了，consumer 从queue 取
		出消息进行消费，但某些时候由于特定的原因导致 queue 中的某些消息无法被消费，这样的消息如果没有后续的处理，就变成了死信，有死信自然就有了死信队列。
		② 应用场景：为了保证订单业务的消息数据不丢失，需要使用到 RabbitMQ 的死信队列机制，当消息消费发送异常时，将消息投入死信队列中，用户在商城下单成功并点击支付后指定时间未支付
		时自动失效
	2. 死信的来源
		① 消息 TTL （存活时间）过期
		② 队列达到最大长度（队列满了，无法再添加数据到 MQ 中）
		③ 消息被拒绝（basic.reject 或者 basic.nack）并且 requeue=false
	3. 死信实战
		① 代码架构图		
							+--------------------------------------------------------------+
							|			type=direct										   |
			+----------+	|	   +-----------------+   normal  +--------------+		   |	  +----+
			| Producer | ---+----> | normal_exchange | --------> | normal_queue | ---------+----> | C1 |
			+----------+	|	   +-----------------+		     +--------------+          |	  +----+
							|											|				   |
							|								消息被拒绝	|				   |
							|							   消息TTL过期	| 成为死信  	   |
							|						   队列达到最大长度 |				   |
							|											↓				   |
							|									+---------------+		   |
							|	broker 				type=direct | dead_exchange | 		   |
							|									+---------------+		   |
							|											|				   |
							|											| dead			   |
							|											↓				   |
							|									  +------------+		   |	  +----+
							|									  | dead_queue | ----------+----> | C2 |
							|									  +------------+		   |      +----+
							+---------------------------------------------------------------
		② 消费者1 
			public class Consumer1 {

				// 普通交换机
				private static final String NORMAL_EXCHANGE_NAME = "normal_exchange";

				// 普通队列
				private static final String NORMAL_QUEUE_NAME = "normal_queue";

				// 死信交换机
				private static final String DEAD_EXCHANGE_NAME = "dead_exchange";

				// 死信队列
				private static final String DEAD_QUEUE_NAME = "dead_queue";

				public static void main(String[] args) throws Exception {

					Channel channel = RabbitMQUtil.getChannel();
					// 普通交换机
					channel.exchangeDeclare(NORMAL_EXCHANGE_NAME, BuiltinExchangeType.DIRECT);
					// 死信交换机
					channel.exchangeDeclare(DEAD_EXCHANGE_NAME, BuiltinExchangeType.DIRECT);

					// 设置参数
					Map<String, Object> arguments = new HashMap<>();
					// 设置过期时间
					// arguments.put("x-message-ttl", 10000);
					// 正常队列设置死信交换机
					arguments.put("x-dead-letter-exchange", DEAD_EXCHANGE_NAME);
					// 设置死信 RoutingKey
					arguments.put("x-dead-letter-routing-key", "dead");
					// 正常队列的最大接收长度
					// arguments.put("x-max-length", 6);
					// 普通队列
					channel.queueDeclare(NORMAL_QUEUE_NAME, false, false, false, arguments);
					// 死信队列
					channel.queueDeclare(DEAD_QUEUE_NAME, false, false, false, null);

					// 绑定普通交换机和普通队列
					channel.queueBind(NORMAL_QUEUE_NAME, NORMAL_EXCHANGE_NAME, "normal");
					// 绑定死信交换机和死信队列
					channel.queueBind(DEAD_QUEUE_NAME, DEAD_EXCHANGE_NAME, "dead");

					System.out.println("Consumer1 等待接收消息……");
					DeliverCallback deliverCallback = (consumerTag, message) -> {
						String msg = new String(message.getBody());
						if (msg.equals("EE")) {
							System.out.println("Consumer1 拒绝的消息：" + msg);
							// 消息拒绝
							channel.basicReject(message.getEnvelope().getDeliveryTag(), false);
						} else {
							System.out.println("Consumer1 接收的消息：" + msg);
							// 消息应答
							channel.basicAck(message.getEnvelope().getDeliveryTag(), false);
						}
					};

					// 消息拒绝一定要开启手动应答
					channel.basicConsume(NORMAL_QUEUE_NAME, false, deliverCallback, consumerTag -> {});
				}
			}
		② 生产者
			public class Producer {

				// 普通交换机
				private static final String NORMAL_EXCHANGE_NAME = "normal_exchange";

				public static void main(String[] args) throws Exception {

					Channel channel = RabbitMQUtil.getChannel();
					channel.exchangeDeclare(NORMAL_EXCHANGE_NAME, BuiltinExchangeType.DIRECT);
					System.out.println("生产者准备发消息……");

					// 死信消息，设置TTL时间
					AMQP.BasicProperties properties = null;
							// new AMQP.BasicProperties().builder().expiration("10000").build();

					Scanner scanner = new Scanner(System.in);
					while (scanner.hasNext()) {
						String message = scanner.next();
						channel.basicPublish(NORMAL_EXCHANGE_NAME, "normal", properties, message.getBytes());
					}
				}
			}
		③ 消费者2
			public class Consumer2 {

				// 死信队列
				private static final String DEAD_QUEUE_NAME = "dead_queue";

				public static void main(String[] args) throws Exception {

					Channel channel = RabbitMQUtil.getChannel();

					System.out.println("Consumer2 等待接收消息……");
					DeliverCallback deliverCallback = (consumerTag, message) -> {
						System.out.println("Consumer2 接收的消息：" + new String(message.getBody()));
					};
					channel.basicConsume(DEAD_QUEUE_NAME, true, deliverCallback, consumerTag -> {});
				}
			}
		④ 消息 TTL 过期设置
			A. 在消息生产中，发送消息时指定 TTL
				AMQP.BasicProperties properties =
							new AMQP.BasicProperties().builder().expiration("10000").build();
			B. 或者在消费者1 中设置队列的 TTL
				Map<String, Object> arguments = new HashMap<>();
				// 设置过期时间
				// arguments.put("x-message-ttl", 10000);
		⑤ 队列达到最大长度设置
			A. 首先在生产者中取消消息过期时间设置
			B. 在消费者1中设置队列最大长度
				// 正常队列的最大接收长度
				arguments.put("x-max-length", 6);
		⑥ 消息被拒设置
			A. 首先在消费者1中取消队列最大长度设置
			B. 在接收消息的回调中，拒绝消息
				DeliverCallback deliverCallback = (consumerTag, message) -> {
					String msg = new String(message.getBody());
					if (msg.equals("EE")) {
						System.out.println("Consumer1 拒绝的消息：" + msg);
						// 消息拒绝
						channel.basicReject(message.getEnvelope().getDeliveryTag(), false);
					} else {
						System.out.println("Consumer1 接收的消息：" + msg);
						// 消息应答
						channel.basicAck(message.getEnvelope().getDeliveryTag(), false);
					}
				};
			C. 开启手动应答
				// 消息拒绝一定要开启手动应答
				channel.basicConsume(NORMAL_QUEUE_NAME, false, deliverCallback, consumerTag -> {});
七、延迟队列
	1. 延迟队列概念：
		延迟队列，队列内部是有序的，最重要的特征就体现在它的延迟属性上，延迟队列中元素最希望在指定时间到了以后或之前取出和处理，简单来说，延时队列就是用来存放在指定时间被处理的元素队
		列。延迟队列是死信队列的一种，即消息的 TTL 过期后的死信队列就是延迟队列
	2. 延迟队列使用场景
		① 订单在十分钟之内未支付则自动取消
		② 新创建的店铺，如果在十天内都没有上传过商品，则自动发消息提醒
		③ 用户注册成功后，如果三天内没有登录则进行短信提醒
		④ 用户发起退款，如果三天内没有得到处理则通知相关运营人员
		⑤ 预定会议后，需要在预定的时间点前十分钟通知各个与会人员的参加
		⑥ 这些场景都有一个特点，需要在某个事件发生之后或者之前的指定时间点内完成某一项任务，如：订单发生订单事件，在十分钟之后检查该订单的支付状态，然后将未支付的订单进行关闭；看起来
		似乎使用定时任务，一直轮询数据，每秒查一次，取出需要被处理的数据，然后处理不就完事了吗？如果数据量比较少，确实可以这样做，比如：对于“如果账单一周内未支付则进行自动结算”这样的
		需求，如果对于时间不是严格限制，而是宽松意义上的一周，那么每天晚上跑个定时任务检查一下所有未支付的账单，确实也是一个可行的方案。但对于数据量比较大，并且时效性较强的场景，如：
		“订单十分钟内未支付则关闭“，短期内未支付的订单数据可能会有很多，活动期间甚至会达到百万甚至千万级别，对这么庞大的数据量仍旧使用轮询的方式显然是不可取的，很可能在一秒内无法完成
		所有订单的检查，同时会给数据库带来很大压力，无法满足业务要求而且性能低下。
	3. RabbitMQ 中的 TTL
		① 单位是毫秒。换句话说，如果一条消息设置了 TTL 属性或者进入了设置 TTL 属性的队列，那么这条消息如果在 TTL 设置的时间内没有被消费，则会成为“死信”。如果同时配置了队列的 TTL 和消
		息的 TTL，那么较小的那个值将会被使用，有两种方式设置 TTL。
		② 消息设置 TTL，针对每条消息设置 TTL
			AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().expiration("10000").build();
		② 队列设置 TTL，在创建队列的时候设置队列的“x-message-ttl”属性
			Map<String, Object> arguments = new HashMap<>();
			arguments.put("x-message-ttl", 10000);
		④ 两者的区别 
			A. 如果设置了队列的 TTL 属性，那么一旦消息过期，就会被队列丢弃(如果配置了死信队列被丢到死信队列中)，而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即
			将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间；另外，还需要注意的一点是，如果不设置 TTL，表示消息永远不会过期，如果将 TTL 
			设置为 0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。
			B. 延时队列，就是想要消息延迟多久被处理，TTL 则刚好能让消息在延迟多久之后成为死信，另一方面，成为死信的消息都会被投递到死信队列里，这样只需要消费者一直消费死信队列里的消息就
			完事了，因为里面的消息都是希望被立即处理的消息。
	4. 整合 springboot
		① 创建 springboot-rabbitmq 模块
		② 添加依赖
			<dependencies>
				<dependency>
					<groupId>org.springframework.boot</groupId>
					<artifactId>spring-boot-starter-web</artifactId>
				</dependency>
				<!--RabbitMQ 依赖-->
				<dependency>
					<groupId>org.springframework.boot</groupId>
					<artifactId>spring-boot-starter-amqp</artifactId>
				</dependency>

				<dependency>
					<groupId>org.springframework.boot</groupId>
					<artifactId>spring-boot-starter-test</artifactId>
					<scope>test</scope>
				</dependency>

				<dependency>
					<groupId>org.projectlombok</groupId>
					<artifactId>lombok</artifactId>
				</dependency>

				<!--RabbitMQ 测试依赖-->
				<dependency>
					<groupId>org.springframework.amqp</groupId>
					<artifactId>spring-rabbit-test</artifactId>
					<scope>test</scope>
				</dependency>

				<!--swagger-->
				<dependency>
					<groupId>io.springfox</groupId>
					<artifactId>springfox-swagger2</artifactId>
					<version>2.9.2</version>
				</dependency>

				<dependency>
					<groupId>io.springfox</groupId>
					<artifactId>springfox-swagger-ui</artifactId>
					<version>2.9.2</version>
				</dependency>

				<dependency>
					<groupId>com.alibaba</groupId>
					<artifactId>fastjson</artifactId>
					<version>1.2.47</version>
				</dependency>

			</dependencies>
		③ 写配置
			spring:
			  rabbitmq:
				host: 10.10.0.26
				port: 5672
				username: admin
				password: 2648
		④ 配置类
			@Configuration
			@EnableSwagger2
			public class SwaggerConfig {

				@Bean
				public Docket webApiConfig() {
					return new Docket(DocumentationType.SWAGGER_2)
							.groupName("webApi")
							.apiInfo(webApiInfo())
							.select()
							.build();
				}

				private ApiInfo webApiInfo() {
					return new ApiInfoBuilder().title("rabbitmq接口文档")
							.description("描述了rabbitmq微服务接口定义")
							.version("1.0")
							.contact(new Contact("li", "http://li.com", "1634491328@qq.com"))
							.build();
				}
			}
	5. 队列 TTL
		① 代码架构图
			A. 创建两个队列 QA 和 QB，两者队列 TTL 分别设置为 10s 和 40s，创建交换机 X 和 死信交换机 Y，它们的类型都是 direct，创建一个死信队列 QD，它们的绑定关系如下：
			B. 架构图
											  XA	 +----+	   YD
										  +--------> | QA | --------+
				+---+		+---+		  |			 +----+			|		+---+	 YD	    +----+		+---+
				| P | ----> | X | --------+							+-------| Y | --------> | QD | ---- | C |
				+---+		+---+		  |			 +----+			|		+---+			+----+		+---+
					type=direct			  +--------> | QB | --------+			  type=direct
											  XB	 +----+    YD
		② 配置文件类
			import org.springframework.amqp.core.*;
			import org.springframework.context.annotation.Bean;
			import org.springframework.context.annotation.Configuration;

			@Configuration
			public class TTLQueueConfig {

				// 普通交换机
				private static final String EXCHANGE_X= "X";
				// 死信交换机
				private static final String DATE_LETTER_EXCHANGE_Y = "Y";
				// 普通队列1
				private static final String QUEUE_A = "QA";
				// 普通队列二
				private static final String QUEUE_B = "QB";
				// 死信队列
				private static final String DATE_LETTER_QUEUE_D = "QD";

				// 声明普通交换机 X
				@Bean("xExchange")
				public DirectExchange xExchange() {
					return new DirectExchange(EXCHANGE_X);
				}

				// 声明私信交换机 Y
				@Bean("yExchange")
				public DirectExchange yExchange() {
					return new DirectExchange(DATE_LETTER_EXCHANGE_Y);
				}

				// 声明普通队列 A，TTL 为 10s
				@Bean("queueA")
				public Queue queueA() {
					return QueueBuilder.nonDurable(QUEUE_A)
							.ttl(10 * 1000)
							.deadLetterExchange(DATE_LETTER_EXCHANGE_Y)
							.deadLetterRoutingKey("YD")
							.build();
				}

				// 声明普通队列 B，TTL 为 40s
				@Bean("queueB")
				public Queue queueB() {
					return QueueBuilder.nonDurable(QUEUE_B)
							.ttl(40 * 1000)
							.deadLetterExchange(DATE_LETTER_EXCHANGE_Y)
							.deadLetterRoutingKey("YD")
							.build();
				}

				// 声明死信队列 D
				@Bean("queueD")
				public Queue queueD() {
					return QueueBuilder.nonDurable(DATE_LETTER_QUEUE_D).build();
				}

				// 普通队列 A 绑定普通交换机 X
				@Bean("queueABindingX")
				public Binding queueABindingX() {
					return BindingBuilder.bind(queueA())
							.to(xExchange())
							.with("XA");
				}

				// 普通队列 B 绑定普通交换机 X
				@Bean("queueBBindingX")
				public Binding queueBBindingX() {
					return BindingBuilder.bind(queueB())
							.to(xExchange())
							.with("XB");
				}

				// 死信队列 D 绑定死信交换机 Y
				@Bean("queueDBindingY")
				public Binding queueDBindingY() {
					return BindingBuilder.bind(queueD())
							.to(yExchange())
							.with("YD");
				}
			}
		③ 消息生产者代码
			import lombok.extern.slf4j.Slf4j;
			import org.springframework.amqp.rabbit.core.RabbitTemplate;
			import org.springframework.web.bind.annotation.GetMapping;
			import org.springframework.web.bind.annotation.PathVariable;
			import org.springframework.web.bind.annotation.RequestMapping;
			import org.springframework.web.bind.annotation.RestController;

			import javax.annotation.Resource;
			import java.time.LocalDateTime;
			import java.time.format.DateTimeFormatter;

			@Slf4j
			@RestController
			@RequestMapping("/ttl")
			public class SendMessageController {

				@Resource
				private RabbitTemplate rabbitTemplate;

				@GetMapping("/sendMessage/{message}")
				public void sendMessage(@PathVariable("message") String message) {
					log.info("当前时间：{}，发送一条消息给两个TTL队列：{}", LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss")), message);

					rabbitTemplate.convertAndSend("X", "XA", "消息来自 ttl 为 10s 的队列：" + message);
					rabbitTemplate.convertAndSend("X", "XB", "消息来自 ttl 为 40s 的队列：" + message);
				}
			}
		④ 消息消费者代码 
			import lombok.extern.slf4j.Slf4j;
			import org.springframework.amqp.core.Message;
			import org.springframework.amqp.rabbit.annotation.RabbitListener;
			import org.springframework.stereotype.Component;

			import java.time.LocalDateTime;
			import java.time.format.DateTimeFormatter;

			@Slf4j
			@Component
			public class DeadLetterQueueConsumer {

				@RabbitListener(queues = "QD")
				public void receiveD(Message message) {
					String msg = new String(message.getBody());
					log.info("当前时间：{}，收到死信队列的消息：{}", LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss")), msg);
				}
			}
		⑤ 发起一个请求 http://localhost:8080/ttl/sendMessage/AA
			当前时间：2021-12-27 15:42:49，发送一条消息给两个TTL队列：AA
			当前时间：2021-12-27 15:42:59，收到死信队列的消息：消息来自 ttl 为 10s 的队列：AA
			当前时间：2021-12-27 15:43:29，收到死信队列的消息：消息来自 ttl 为 40s 的队列：AA
		⑥ 第一条消息在 10S 后变成了死信消息，然后被消费者消费掉，第二条消息在 40S 之后变成了死信消息，然后被消费掉，这样一个延时队列就打造完成了。
		⑦ 不过，如果这样使用的话，岂不是每增加一个新的时间需求，就要新增一个队列，这里只有 10S 和 40S 两个时间选项，如果需要一个小时后处理，那么就需要增加 TTL 为一个小时的队列，如果是预
		定会议室然后提前通知这样的场景，岂不是要增加无数个队列才能满足需求？
	6. 延时队列优化
		① 代码架构图
			A. 这里新增了一个队列 QC ，绑定关系如下，该队列不设置 TTL 时间
			B. 架构图
											 XA	    +----+	   YD
										 +--------> | QA | ---------+
										 |			+----+			|				 
										 |							| 
				+---+		+---+		 |	 XB		+----+			|			+---+	 YD	    +----+		 +---+	 
				| P | ----> | X | -------+--------> | QB | ---------+---------> | Y | --------> | QD | ----> | C |
				+---+		+---+		 |	  		+----+    YD	|			+---+			+----+		 +---+
					type=direct			 |							|				type=direct
										 |	 XC	    +----+			|
										 +--------> | QC | ---------+
													+----+    YD
		② 配置文件类代码
			// 普通队列C
			private static final String QUEUE_C = "QC";
			
			// 声明普通队列 B，不设置 TTL
			@Bean("queueC")
			public Queue queueC() {
				return QueueBuilder.nonDurable(QUEUE_C)
						.deadLetterExchange(DATE_LETTER_EXCHANGE_Y)
						.deadLetterRoutingKey("YD")
						.build();
			}
			
			// 普通队列 C 绑定普通交换机 X
			@Bean("queueCBindingX")
			public Binding queueCBindingX() {
				return BindingBuilder.bind(queueC())
						.to(xExchange())
						.with("XC");
			}
		③ 生产者
			@GetMapping("/sendExpireMessage/{message}/{ttlTime}")
			public void sendExpireMessage(@PathVariable("message") String msg, @PathVariable("ttlTime") String ttlTime) {
				log.info("当前时间：{}，发送一条时长{}毫秒的信息给队列QC：{}", LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss")), ttlTime, msg);
				rabbitTemplate.convertAndSend("X", "XC", msg, message -> {
					message.getMessageProperties().setExpiration(ttlTime);
					return message;
				});
			}
		④ 发起请求
			http://localhost:8080/ttl/sendExpireMessage/AA/20000
			http://localhost:8080/ttl/sendExpireMessage/BB/2000
		⑤ 结果
			当前时间：2021-12-27 16:21:22，发送一条时长20000毫秒的信息给队列QC：AA
			当前时间：2021-12-27 16:21:24，发送一条时长2000毫秒的信息给队列QC：BB
			当前时间：2021-12-27 16:21:42，收到死信队列的消息：AA
			当前时间：2021-12-27 16:21:42，收到死信队列的消息：BB
		⑥ 在消息属性上设置 TTL 的方式，消息可能不会按时 “死亡”，因为 RabbitMQ 只会检查第一消息是否过期，如果过期则丢到死信队列，如果第一个消息的延时时长很长，而第二个消息的延时时长很
		短，第二个消息不会优先得到执行
	7. RabbitMQ 实现延迟队列
		① 延迟队列的缺陷：如果不能实现在消息粒度上的 TTL，并使其在设置的 TTL 时间及时死亡，就无法设计成一个通用的延时队列。
		② 安装延时队列插件
			A. 在官网上下载 https://www.rabbitmq.com/community-plugins.html，下载rabbitmq_delayed_message_exchange 插件，然后放置到 RabbitMQ 的插件目录。
			/usr/lib/rabbitmq/lib/rabbitmq_server-3.8.22/plugins/
			B. 进入 RabbitMQ 的安装目录下的 plgins 目录，执行下面命令让该插件生效，然后重启 RabbitMQ
				cd /usr/lib/rabbitmq/lib/rabbitmq_server-3.8.22/plugins/
				rabbitmq-plugins enable rabbitmq_delayed_message_exchange
				server rabbitmq-server restart
			C. 安装插件完成之后，在交换机类型中新增了一种类型：x-delayed-message，这是一种新的交换机类型，该类型消息支持延迟投递机制，消息传递后并不会立即投递到目标队列中，而是存储在
			mnesia（分布式数据系统）表中，当达到投递时间时，才投递到目标队列中。
		③ 代码架构图 
			A. 增了队列 delayed.queue,一个自定义交换机 delayed.exchange
			B. 绑定关系如下			
				+---+	   +------------------+					+---------------+			  +---+
				| P | ---- | delayed.exchange | --------------- | delayed.queue | ----------- | C |
				+---+	   +------------------+		delayed		+---------------+			  +---+
						  type=x-delayed-message
		④ 配置文件类代码
			import org.springframework.amqp.core.*;
			import org.springframework.context.annotation.Bean;
			import org.springframework.context.annotation.Configuration;

			import java.util.HashMap;
			import java.util.Map;

			@Configuration
			public class DelayedConfig {

				// 延迟交换机
				private static final String DELAYED_EXCHANGE_NAME = "delayed_exchange";
				// 延迟队列
				private static final String DELAYED_QUEUE_NAME = "delayed_queue";
				// 延迟路由
				private static final String DELAYED_ROUTING_KEY = "delayed";

				// 声明延迟交换机，基于延迟插件
				@Bean("delayedExchange")
				public CustomExchange delayedExchange() {
					Map<String, Object> arguments = new HashMap<>();
					// 定义延迟类型
					arguments.put("x-delayed-type", "direct");
					/*
					 * name：交换机类型
					 * type：交换机类型
					 * durable：是否需要持久化
					 * autoDelete：是否自动删除交换机
					 * arguments：其他参数
					 */
					return new CustomExchange(DELAYED_EXCHANGE_NAME, "x-delayed-message", false, false, arguments);
				}

				// 声明延迟队列，基于延迟插件
				@Bean("delayedQueue")
				public Queue delayedQueue() {
					return QueueBuilder.nonDurable(DELAYED_QUEUE_NAME).build();
				}

				// 延迟队列绑定到延迟交换机
				@Bean("bindingDelayedExchange")
				public Binding bindingDelayedExchange() {
					return BindingBuilder.bind(delayedQueue()).to(delayedExchange()).with(DELAYED_ROUTING_KEY).noargs();
				}
			}
		⑤ 生产者：
			@GetMapping("/sendDelayedMessage/{message}/{delayedTime}")
			public void sendDelayedMessage(@PathVariable("message") String msg, @PathVariable("delayedTime") Integer delayedTime) {
				log.info("当前时间：{}，发送一条时长{}毫秒的信息给延迟队列delayed_queue：{}", LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss")), delayedTime, msg);
				rabbitTemplate.convertAndSend("delayed_exchange", "delayed", msg, message -> {
					// 设置延迟时间
					message.getMessageProperties().setDelay(delayedTime);
					return message;
				});
			}
		⑥ 消费者
			@RabbitListener(queues = "delayed_queue")
			public void receiveDelayedQueue(Message message) {
				String msg = new String(message.getBody());
				log.info("当前时间：{}，收到延迟队列的消息：{}", LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss")), msg);
			}
		⑦ 发起请求
			http://localhost:8080/ttl/sendDelayedMessage/CC/20000
			http://localhost:8080/ttl/sendDelayedMessage/DD/2000
		⑧ 结果
			当前时间：2021-12-27 17:59:21，发送一条时长20000毫秒的信息给延迟队列delayed_queue：CC
			当前时间：2021-12-27 17:59:23，发送一条时长2000毫秒的信息给延迟队列delayed_queue：DD
			当前时间：2021-12-27 17:59:25，收到延迟队列的消息：DD
			当前时间：2021-12-27 17:59:41，收到延迟队列的消息：CC
			第二个消息被消费掉，符合预期
	8. 总结
		① 延时队列在需要延时处理的场景下非常有用，使用 RabbitMQ 来实现延时队列可以很好的利用 RabbitMQ 的特性，如：消息可靠发送、消息可靠投递、死信队列来保障信息至少被消费一次以及未
		被正确处理的消息不会被丢弃。另外，通过 RabbitMQ 集群的特征，可以很好解决单点故障问题，不会因为单个节点挂掉导致延时队列不可用或者消息丢失
		② 当然，延时队列还有很多其他选择，比如利用 Java 的 DelayQueue，利用 Redis 的 zset，利用 Quartz 或者 利用 kafka 的时间轮，这些方式各有特点。
八、发布确认高级
	1. 简介：在生产环境中由于一些不明原因，导致 RabbitMQ 重启期间生产者消息投递失败，导致消息丢失，需要手动处理和恢复。于是，如何进行 RabbitMQ 的消息可靠投递，特别是在 RabbitMQ集群
	不可用的极端情况下，无法投递的消息该如何处理
	2. 发布确认 springboot 版本
		① 确认机制方案
			+---+		     +------------------+		    +---------------+		    +------------------+
			| P | ----+----> | confirm.exchange | --------> | confirm.queue | --------> | confirm consumer |
			+---+	  |	     +------------------+		    +---------------+		    +------------------+
					  |				|
					  |				| 当交换机收到消息
					  ↓				| 从缓存中清楚已收到的消息
				   +------+	  		|
				   | 缓存 | <-------+
				   +------+
					  | 定时任务对未成功
					  | 发送的消息重新投递
		② 代码架构图
			+---+		     +------------------+		    +---------------+		    +------------------+
			| P | ---------> | confirm.exchange | --------> | confirm.queue | --------> | confirm consumer |
			+---+	  	     +------------------+		    +---------------+		    +------------------+
								 type=direct	   confirm
		③ 写配置
			A. 在配置文件当中需要添加
				spring:
				  rabbitmq:
					publisher-confirm-type: correlated
			B. 发布确认类型
				a. NONE：禁用发布确认模式，是默认值
				b. CORRELATED：发布消息成功到交换器后会触发回调方法
				c. SIMPLE
					(1) 单个确认，同步等待
					(2) 经测试有两种效果，其一效果和 CORRELATED 值一样会触发回调方法，其二在发布消息成功后使用 rabbitTemplate 调用 waitForConfirms 或 waitForConfirmsOrDie 方法等待 broker 
					节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是waitForConfirmsOrDie 方法如果返回 false 则会关闭 channel，则接下来无法发送消息到 broker
		④ 配置类
			@Configuration
			public class ConfirmConfig {

				// 交换机
				private static final String CONFIRM_EXCHANGE_NAME = "confirm_exchange";

				// 队列
				private static final String CONFIRM_QUEUE_NAME = "confirm_queue";

				// 路由
				private static final String CONFIRM_ROUTING_KEY = "confirm";

				// 声明交换机
				@Bean("confirmExchange")
				public DirectExchange confirmExchange() {
					return new DirectExchange(CONFIRM_EXCHANGE_NAME);
				}

				// 声明队列
				@Bean("confirmQueue")
				public Queue confirmQueue() {
					return QueueBuilder.nonDurable(CONFIRM_QUEUE_NAME).build();
				}

				// 绑定队列和交换机
				@Bean("bindingConfirmExchange")
				public Binding bindingConfirmExchange() {
					return BindingBuilder.bind(confirmQueue()).to(confirmExchange()).with(CONFIRM_ROUTING_KEY);
				}
			}
		⑤ 消息生产者 
			@Slf4j
			@RestController
			@RequestMapping("/confirm")
			public class ConfirmController {

				@Resource
				private RabbitTemplate rabbitTemplate;

				@GetMapping("/sendConfirmMsg/{msg}")
				public void sendConfirmMsg(@PathVariable("msg") String msg) {
					log.info("发送消息：{}", msg);
					CorrelationData correlationData = new CorrelationData("1");
					rabbitTemplate.convertAndSend("confirm_exchange", "confirm1", msg, correlationData);
				}
			}
		⑥ 消息消费者 
			@Slf4j
			@Component
			public class ConfirmConsumer {

				@RabbitListener(queues = "confirm_queue")
				public void receiveConfirmMsg(Message message) {
					log.info("接收到消息：{}", new String(message.getBody()));
				}
			}
		⑦ 回调接口 
			@Slf4j
			@Component
			public class MyCallBack implements RabbitTemplate.ConfirmCallback {

				@Resource
				private RabbitTemplate rabbitTemplate;

				@PostConstruct
				public void init() {
					// 将回调注入rabbit
					rabbitTemplate.setConfirmCallback(this);
				}

				/**
				 * 交换机确认回调方法
				 * 发消息，交换机接收成功或者失败的回调
				 *  correlationData：保存回调消息的ID及相关信息
				 *  ack：交换机是否接收到消息，true：接收成功，false：接收失败
				 *  cause：null/失败的原因
				 */
				@Override
				public void confirm(CorrelationData correlationData, boolean ack, String cause) {
					String id = correlationData == null ? null : correlationData.getId();
					if (ack) {
						log.info("交换机已经收到Id为{}的消息", id);
					} else {
						log.info("交换机还未收到Id为{}的消息，原因为：{}", id, cause);
					}
				}
			}
		⑧ 结果分析
			A. 结果
				发送消息：AA
				交换机已经收到Id为1的消息
				接收到消息：AA

				发送消息：BB
				交换机已经收到Id为1的消息
			B. 分析：可以看到，发送了两条消息，第一条消息的 RoutingKey 为 “confirm”，第二条消息的 RoutingKey 为 “confirm1”，两条消息都成功被交换机接收，也收到了交换机的确认回调，
			但消费者只收到一条消息，因为第二条消息的 RoutingKey 与队列的 BindingKey 不一致，也没有其他队列能够接收这个消息，所以第二条消息直接被丢弃了。
	3. 回退消息
		① Mandatory 参数：在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，如果发现该消息不可路由，那么消息会被直接丢弃，此时生产者是不知道
		消息被丢弃这个事件的。通过设置 mandatory 参数可以在当消息传递过程中不可到达目的地时将消息返回给生产者
		② 改配置
			spring:
			  rabbitmq:
				publisher-returns: true
		③ 回调接口
			@Slf4j
			@Component
			public class MyCallBack implements RabbitTemplate.ConfirmCallback, RabbitTemplate.ReturnsCallback {

				@Resource
				private RabbitTemplate rabbitTemplate;

				@PostConstruct
				public void init() {
					// 将回调注入rabbit
					rabbitTemplate.setConfirmCallback(this);
					/*
					 * true：交换机无法将消息进行路由时，会将该消息返回给生产者
					 * false：如果发现消息无法进行路由，则直接丢弃
					 */
					rabbitTemplate.setMandatory(true);
					rabbitTemplate.setReturnsCallback(this);
				}

				/**
				 * 交换机确认回调方法
				 * 发消息，交换机接收成功或者失败的回调
				 *  correlationData：保存回调消息的ID及相关信息
				 *  ack：交换机是否接收到消息，true：接收成功，false：接收失败
				 *  cause：null/失败的原因
				 */
				@Override
				public void confirm(CorrelationData correlationData, boolean ack, String cause) {
					String id = correlationData == null ? null : correlationData.getId();
					if (ack) {
						log.info("交换机已经收到Id为{}的消息", id);
					} else {
						log.info("交换机还未收到Id为{}的消息，原因为：{}", id, cause);
						// 在此可以进行消息缓存或者重新发送
					}
				}

				@Override
				public void returnedMessage(ReturnedMessage returnedMessage) {
					log.info("消息：{}被交换机{}退回，原因是{}",
							new String(returnedMessage.getMessage().getBody()), returnedMessage.getExchange(), returnedMessage.getReplyText());
				}
			}
		④ 结果分析
			发送消息：BB
			消息：BB被交换机confirm_exchange退回，原因是NO_ROUTE
			交换机已经收到Id为1的消息
	4. 备份交换机
		① 有了 mandatory 参数和回退消息，我们获得了对无法投递消息的感知能力，有机会在生产者的消息无法被投递时发现并处理。但是有时候，我们并不知道该如何处理这些无法路由的消息，
		最多打个日志，然后触发报警，再来手动处理。而通过日志来处理这些无法路由的消息是很不优雅的做法，特别是当生产者所在的服务有多台机器的时候，手动复制日志会更麻烦而且容易出
		错。而且设置 mandatory 参数会增加生产者的复杂性，需要添加处理这些被退回的消息的逻辑。如果既不想丢失消息，又不想增加生产者的复杂性，前面在死信队列中，，可以为队列设置
		死信交换机来存储那些处理失败的消息，可是这些不可路由消息根本没有机会进入到队列，因此无法使用死信队列来保存消息。在 RabbitMQ 中，有一种备份交换机的机制存在，可以很好的
		应对这个问题。备份交换机可以理解为 RabbitMQ 中交换机的“备胎”，当我们为某一个交换机声明一个对应的备份交换机时，就是为它创建一个备胎，当交换机接收到一条不可路由消息时，
		将会把这条消息转发到备份交换机中，由备份交换机来进行转发和处理，通常备份交换机的类型为 Fanout ，这样就能把所有消息都投递到与其绑定的队列中，然后我们在备份交换机下绑定
		一个队列，这样所有那些原交换机无法被路由的消息，就会都进入这个队列了。当然，我们还可以建立一个报警队列，用独立的消费者来进行监测和报警。
		② 代码架构图
								  type=direct	   confirm
			+---+		     +------------------+		    +---------------+		    +------------------+
			| P | ---------> | confirm.exchange | --------> | confirm.queue | --------> | confirm consumer |
			+---+	  	     +------------------+		    +---------------+		    +------------------+
									   |
					无法投递的消息将   |
					发送给备份交换机   |					+--------------+			 +--+
									   ↓			  +---> | backup.queue | ----------> |	|
							  +-----------------+	  |		+--------------+			 +--+
							  | backup.exchange | ----+
							  +-----------------+	  |		+---------------+			  +------------------+
								  type=fanout		  +---> | warning.queue | ----------> |	warning consumer |
															+---------------+			  +------------------+
		③ 修改配置类
			// 备份交换机
			private static final String BACKUP_EXCHANGE_NAME = "backup_exchange";

			// 备份队列
			private static final String BACKUP_QUEUE_NAME = "backup_queue";

			// 告警队列
			private static final String WARNING_QUEUE_NAME = "warning_queue";

			// 声明交换机
			@Bean("confirmExchange")
			public DirectExchange confirmExchange() {
				return ExchangeBuilder.directExchange(CONFIRM_EXCHANGE_NAME).alternate(BACKUP_EXCHANGE_NAME).build();
			}
			
			// 声明备份队列
			@Bean("backupExchange")
			public FanoutExchange backupExchange() {
				return new FanoutExchange(BACKUP_EXCHANGE_NAME);
			}

			// 声明备份队列
			@Bean("backupQueue")
			public Queue backupQueue() {
				return QueueBuilder.nonDurable(BACKUP_QUEUE_NAME).build();
			}

			// 声明告警队列
			@Bean("warningQueue")
			public Queue warningQueue() {
				return QueueBuilder.nonDurable(WARNING_QUEUE_NAME).build();
			}

			// 备份队列绑定到备份交换机
			@Bean("backupQueueBinding")
			public Binding backupQueueBinding() {
				return BindingBuilder.bind(backupQueue()).to(backupExchange());
			}

			// 告警队列绑定到备份交换机
			@Bean("warningQueueBinding")
			public Binding warningQueueBinding() {
				return BindingBuilder.bind(warningQueue()).to(backupExchange());
			}
		④ 报警消费者	
			@RabbitListener(queues = "warning_queue")
			public void receiveWarningMsg(Message message) {
				String msg = new String(message.getBody());
				log.info("报警发现不可路由消息：{}", msg);
			}
		⑤ 测试注意事项
			重新启动项目的时候需要把原来的 confirm.exchange 删除因为我们修改了其绑定属性，不然报以下错:
		⑥ 结果分析
			A. 结果
				发送消息：BB
				交换机已经收到Id为1的消息
				报警发现不可路由消息：BB
			B. 结论：mandatory 参数与备份交换机可以一起使用的时候，如果两者同时开启，是备份交换机优先级高。
九、RabbitMQ 其他知识点
	1. 幂等性
		① 概念：用户对于统一操作发起一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个简单的例子，用户购买商品后支付，支付扣款成功，但是返回结果的
		时候网络异常，此时钱已经扣了，用户再次点击按钮，会进行第二次扣款，返回结果成功，用户查询余额时发现多扣钱，流水记录也变成了两条。在以前的单应用系统中，我们只需要
		把数据放入事务中即可，发生错误立即回滚，但是在响应客户的时候也有可能出现网络中断或者异常等等
		② 消息重复消费：消费者在消费 RabbitMQ 中的消息时，MQ 已把消息发送给消费者，消费者在给 MQ 返回 ack 时网络中断，姑 MQ 未收到确认信息，该条消息会重新发给其他消费者
		或者在网络重连后再次发送给消费者，但实际上该消费者已经成功消费了该条消息，造成消费者消费了重复的消息
		③ 解决思路：MQ 消费者的幂等性的解决一般使用全局 ID 或者写个唯一标识比如时间戳或者 UUID 或者订单消费者消费 MQ 中的消息也可以利用 MQ 的该 id 来判断，或者可按自己的
		规则生成一个全局唯一 id，每次消费消息时用该 id 先判断该消息是否已经消费过
		④ 消费端的幂等性保障：在海量订单生产的业务高峰期，生产端可能就会重复发送了消息，这时候消费端就要实现幂等性，这就意味着我们的消息永远不会被消费多次，即时我们收到
		了一样的消息。业界主流的幂等性有两种操作：a.唯一ID+指纹码机制，利用数据库主键去重；b.利用 redis 的原子性去重
		⑤ 唯一 ID+指纹码机制：指纹码，我们的一些队则或者时间戳加别的服务给到的唯一信息码，它并不一定是我们系统生产的，基本都是由我们的业务规则拼接而来，但是一定要保证唯一
		性，然后就利用查询语句进行判断这个id 是否存在数据库中，优势就是实现一个简单拼接，然后查询判断是否重复，劣势就是在实行高并发时，如果单个数据库就会有写入性能瓶颈，
		当然也可以采用分库分表提升性能，但也不是最推荐的方式。
		⑥ Redis 原子性：利用redis 执行setnx，天然具有幂等性，从而实现不重复消费。
	2. 优先级队列
		① 使用场景：在系统中有一个订单催付的场景，客户在天猫下的订单，淘宝会及时将订单推送给我们，如果在用户设定的时间内未付款，那么就会给用户发送一条消息提醒。但是天猫
		商家肯定要分大客户和小客户，比如像苹果，小米这样的大商家一年起码能创造很大的利润，所以理所当然，他们的订单必须得到优先处理，而曾经我们的后端系统就是使用 redis 来
		存放定时轮询，都知道 redis 只能用 List 做一个简单的消息队列，并不能实现一个优先级的场景，所以订单量大了后来采用 RabbitMQ 进行改造和优化，如果发现是大客户的订单给
		一个相对高的优先级，否则就是默认优先级
		② 要让队列实现优先级需要做的事情有如下事情:队列需要设置为优先级队列，消息需要设置消息的优先级，消费者需要等待消息已经发送到队列中才去消费因为，这样才有机会对消息
		进行排序
		③ 实战
			A. 配置类：
				@Configuration
				public class PriorityConfig {

					// 优先级队列
					private static final String PRIORITY_QUEUE_NAME = "priority_queue";

					@Bean("priorityQueue")
					public Queue priorityQueue() {
						return QueueBuilder.nonDurable(PRIORITY_QUEUE_NAME).maxPriority(10).build();
					}
				}
			B. 生产者
				public void testPriority() {

					for (int i = 1; i < 11; i++) {
						if (i % 5 == 0) {
							rabbitTemplate.convertAndSend("", "priority_queue", i + "", message -> {
								message.getMessageProperties().setPriority(10);
								return message;
							});
						} else {
							rabbitTemplate.convertAndSend("", "priority_queue", i + "");
						}
					}
				}
			C. 消费者
				@RabbitListener(queues = "priority_queue")
				public void receivePriorityMeg(Message message) {
					System.out.println(new String(message.getBody()));
				}
	3. 惰性队列
		① 使用场景
			A. RabbitMQ 从 3.6.0 版本开始引入了惰性队列的概念。惰性队列会尽可能的将消息存入磁盘中，而在消息消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标
			是能够支持更长的队列，机支持更多的消息存储。当消费者由于各种各样的原因（比如消费者下线了、宕机亦或由于维护而关闭）而导致长时间内不能消费消息造成堆积时，惰性队列
			就很有必要了
			B. 默认情况下，当生产者将消息发送到 RabbitMQ 的时候，队列中的消息会尽可能的存储在内存中，这样可以更加快速的将消息发送给消费者。即时是持久化的消息，在被写入磁盘
			的同时也会在内存中驻留一份备份。当 RabbitMQ 需要释放内存的时候，会将内存中的消息换页至磁盘中，这个操作会耗费较长的时间m也会阻塞队列的操作，进而无法接收新的消息。
			虽然 RabbitMQ 的开发者们一直在升级相关的算法，但是效果始终不理想，尤其是在消息量特别大的时候。
		② 两种模式：
			A. 队列具有两种模式，default 和 lazy。默认的为 default 模式，在 3.6.0 之前的版本无需做任务变更，lazy 模式即为惰性队列的模式，可以通过调用 Chanel.queueDeclare 方
			法的时候在参数中设置，也可以通过 policy 方式设置，如果一个队列同时使用这两种方式设置的话，那么 policy 的方式具备更高的优先级。如果通过声明的方式改变已有队列的模式
			的话，那么只能删除队列，然后在重新声明一个新的
			B. 在队列声明的时候可以通过“x-queue-mode”参数来设置队列的模式，取值为“default”和“lazy”。
				@Bean("lazyQueue")
				public Queue lazyQueue() {
					return QueueBuilder.nonDurable(LAZY_QUEUE_NAME).lazy().build();
				}
		③ 内存开销对比：在发送1百万条消息，每条消息大概占1KB的情况下，普通队列占用内存是1.2GB，而惰性队列仅仅占用1.5MB，因为惰性队列把消息存在磁盘，而内存仅仅保存消息的索引。
十、RabbitMQ 集器
	1. clustering
		① 使用集群的原因：前面安装和运行 RabbitMQ 服务，都是单机版，无法满足目前真实应用的要求。如果 RabbitMQ 服务器遇到内存崩溃、机器掉电或者主板故障。单台 RabbitMQ 服务器
		可以满足每秒 1000条消息的吞吐量，那么如果应用需要 RabbitMQ 服务满足每秒 10万 条消息的吞吐量，购买昂贵的服务器来增强单机 RabbitMQ 的性能显得不可靠，搭建一个 RabbitMQ
		集群才是实际解决问题的关键
		② 搭建步骤
			A. 修改 3 台机器的主机名称分别为 node1、node2、node3
				vim /etc/hostname
			B. 配置各个节点的 hosts 文件，让各个节点都能互相识别对方
				vim /etc/hosts
				192.168.230.101 hadoop101
				192.168.230.102 hadoop102
				192.168.230.103 hadoop103
			C. 以确保各个节点的 cookie 文件使用的是同一个值，在 node1 上执行远程操作命令
				scp /var/lib/rabbitmq/.erlang.cookie root@hadoop102:/var/lib/rabbitmq/.erlang.cookie
				scp /var/lib/rabbitmq/.erlang.cookie root@hadoop103:/var/lib/rabbitmq/.erlang.cookie
			D. 启动 RabbitMQ 服务,顺带启动 Erlang 虚拟机和 RbbitMQ 应用服务(在三台节点上分别执行以下命令)
				rabbitmq-server -detached
			E. 在节点 2 执行
				rabbitmqctl stop_app，rabbitmqctl stop 会将 Erlang 虚拟机关闭，rabbitmqctl stop_app 只关闭 RabbitMQ 服务
				rabbitmqctl reset
				rabbitmqctl join_cluster rabbit@node1
				rabbitmqctl start_app(只启动应用服务)
			F. 在节点 3 执行
				rabbitmqctl stop_app
				rabbitmqctl reset
				rabbitmqctl join_cluster rabbit@node2
				rabbitmqctl start_app
			G. 集群状态
				rabbitmqctl cluster_status
			H. 需要重新设置用户
				a. 创建账号
					rabbitmqctl add_user admin 2648
				b. 设置用户角色
					rabbitmqctl set_user_tags admin administrator
				c. 设置用户权限
					rabbitmqctl set_permissions -p "/" admin ".*" ".*" ".*"
			I. 解除集群节点(node2 和 node3 机器分别执行)
				rabbitmqctl stop_app
				rabbitmqctl reset
				rabbitmqctl start_app
				rabbitmqctl cluster_status
				node1和node2执行
				rabbitmqctl forget_cluster_node rabbit@node2
	2. 镜像队列
		① 使用镜像得原因：
			A. 如果 RabbitMQ 集群中只有一个 Broker 节点，那么该节点的失效将导致整体服务的临时性不可用，并且也可能会导致消息的丢失。可以将消息都设置为持久化，并且
			对应队列的 durable 属性也设置为 true，但是这样仍然无法避免由于缓存导致的问题：因为消息在发送之后和被写入磁盘并执行刷盘动作之间存在一个短暂却会产生问题的时间窗。通过
			publisher/confirm 机制能够确保客户端知道哪些消息已经存入磁盘，尽管如此，一般不希望遇到因单点故障导致服务不可用
			B. 引入镜像队列（mirror Queue）的机制，可以将队列镜像到集群中其他 Broker节点之上，如果集群中一个节点失效了，队列能自动地切换到镜像中的另一个节点上以保证服务的可用性
		② 搭建步骤 
			A. 启动三台集群节点
			B. 随便找一个节点添加 policy
				点击 Admin -> 点击右侧的 policies -> 点击左侧的 Add / update a policy
			C. 输入策略名称，以及镜像队列名称的正则表达式，选择应用在 Exchanges and queues 上
			D. 定义
				a. ha-mode=exactly：指定备份模式
				b. ha-params=2：备份份数
				c. ha-sync-mode=automatic
			E. 在 node1 上创建一个队列发送一条消息，队列存在镜像队列，消息会自动备份到 node2
			F. 停掉 node1 之后发现 node2 成为镜像队列，并且会自动备份到 node3
			G. 就算整个集群只剩下一台机器了 依然能消费队列里面的消息，说明队列里面的消息被镜像队列传递到相应机器里面了
	3. Haproxy+Keepalive 实现高可用负载均衡
		① Haproxy 实现负载均衡 
			A. HAProxy 提供高可用性、负载均衡及基于 TCPHTTP 应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案，包括 Twitter,Reddit,StackOverflow,GitHub 在内的多
			家知名互联网公司在使用。HAProxy 实现了一种事件驱动、单一进程模型，此模型支持非常大的井发连接数。
			B. 扩展 nginx,lvs,haproxy 之间的区别: http://www.ha97.com/5646.html
		② 搭建步骤 
			A. 下载 haproxy(在 node1 和 node2)
				yum -y install haproxy
			B. 修改 node1 和 node2 的 haproxy.cfg
				vim /etc/haproxy/haproxy.cfg
				###################### 打开haproxy的监测界面###############################
				listen status
				bind 0.0.0.0:8888
				mode http
				stats enable
				stats refresh 30s
				stats uri /stats                     #设置haproxy监控地址为http://localhost:8888/stats
				stats auth admin:2648                #添加用户名密码认证
				stats realm (Haproxy\ statistic)
				stats admin if TRUE

				######################监听rabbitmq的web操作页面############################
				listen rabbitmq_admin
					bind 0.0.0.0:15670
					server rabbit_hadoop101 hadoop101:15672
					server rabbit_hadoop102 hadoop102:15672
					server rabbit_hadoop103 hadoop103:15672

				#######################监听rabbimq_cluster #################################
				listen rabbitmq_cluster
				bind 0.0.0.0:5670
				mode tcp
				balance roundrobin  #负载均衡算法（#banlance roundrobin 轮询，balance source 保存session值，支持static-rr，leastconn，first，uri等参数）
				server rabbit_hadoop101 hadoop101:5672 check inter 5000 rise 2 fall 3 weight 1  #check inter 2000 是检测心跳频率
				server rabbit_hadoop102 hadoop102:5672 check inter 5000 rise 2 fall 3 weight 1  #rise 2是2次正确认为服务器可用
				server rabbit_hadoop103 hadoop103:5672 check inter 5000 rise 2 fall 3 weight 1  #fall 2是2次失败认为服务器不可用
			C. 在两台节点启动 haproxy
				haproxy -f /etc/haproxy/haproxy.cfg
				ps -ef | grep haproxy
			D. 访问地址
				http://10.211.55.71:8888/stats 
		③ Keepalived 
	4. Federation Exchange
		① 使用联邦交换机的原因
			A. （broker 北京和 broker 深圳）两台交换机之间相距甚远，网络延迟是一个不得不面对的问题。有一个北京的业务（Client 北京）需要连接（broker 北京），向其中的交换机 
			exchangeA 发消息，此时网络延迟很小，（Client 北京）可以迅速将消息发送至 ExchangeA中，就算在开启了 publisher/confirm 机制或者事务机制的情况下，也可以迅速收到确
			认信息。此时又有个深圳的业务（Client 深圳）需要向 exchangeA 发送消息。那么（Client 深圳 broker 北京）之间有很大的网络延迟，（Client 深圳）将发送消息至 exchangeA 
			会经历一定的延迟，尤其是在开启了 publisher/confirm 机制或者事务机制的情况下，（client 深圳）会等待很长的延迟时间来接收（broker 北京）的确认信息，进而必然造成这条
			发送线程的性能降低，甚至造成一定程度上的阻塞
			B. 将业务（Client 深圳）部署到北京的机房可以解决这个问题，但是如果（Client 深圳）调用的另些服务部署在深圳，那么又会引发新的网络延时问题，因此使用 Federation 插件。
		② 搭建步骤
			A. 需要保证每台节点单独运行
			B. 在每台机器上开启 federation 相关插件
				rabbitmq-plugins enable rabbitmq_federation
				rabbitmq-plugins enable rabbitmq_federation_management
			C. 原理图，先在 node2 创建交换机 fed_exchange
				+-------------------------------------------------------------------+
				|																	|
				|	  消息	  +--------------+	  routingKey	 +-------------+	|
				|	--------> | fed_exchange | ----------------> | node1_queue |	|
				|			  +--------------+					 +-------------+	|
				|					 |												|
				|					 |								   node1		|
				|					 ↓								 upstream		|
				|	+-----------------------------------------+						|
				|	| federation:fed_exchange -> rabbit@node2 |						|
				|	+-----------------------------------------+						|
				+--------------------|----------------------------------------------+
				+--------------------|----------------------------------------------+
				|					 |								   node2		|
				|					 ↓								 downstream		|
				|			  +--------------+	  routingKey	 +--------------+	|
				|			  | fed_exchange | ----------------> |  node2_queue |	|
				|			  +--------------+					 +--------------+	|
				+-------------------------------------------------------------------+
			D. 在 downstream(node2)配置 upstream(node1)
				a. 点击 node2 Admin -> 点击 Federation upstreams -> 选择 Add a new upstream
				b. 在 General parameters 中，分别在 Name 和 URI 中输入上游名字 node1-as-upstream 和上游 URI amqp://admin:[redacted]@hadoop101
				c. 点击 Add upstream
			E. 在 downstream(node2)添加 policy
				a. 点击 node2 Admin -> 点击 Policies -> 选择 Add / update a policy
				b. 在 Name 和 Pattern分别输入策略名字 exchange-policy 和 策略的正则^fed.*，apply to 选择 Exchange
				c. 添加Definition，选择 Federation upstream=node1-as-upstream，
				d. 点击 Add / update a policy
			F. 最后点击 Federation Status 查看搭建的状态
	5. Federation Queue
		① 使用它的原因：联邦队列可以在多个 Broker 节点(或者集群)之间为单个队列提供均衡负载的功能。一个联邦队列可以连接一个或者多个上游队列(upstream queue)，并从这些上游队列中获取
		消息以满足本地消费者消费消息的需求。
		② 搭建步骤
			A. 原理图		
								node1 upstream						downstream node2
								 +-----------+	队列被联邦到 node1	+-----------+
				这台消息发送消息 | fed.queue | <------------------- | fed.queue | 这台机器先创建队列
								 +-----------+						+-----------+
										|								  |
										|	 消息者达到消息消费负载均衡   |
									consumer1							consumer2
			B. 添加 upstream(同上)
			C. 添加 policy
				a. 点击 node2 Admin -> 点击 Policies -> 选择 Add / update a policy
				b. 在 Name 和 Pattern分别输入策略名字 queue-policy 和 策略的正则^fed.*，apply to 选择 Queue
				c. 添加Definition，选择 Federation upstream=node1-as-upstream，
				d. 点击 Add / update a policy
	6. Shovel
		① 使用它的原因：Federation 具备的数据转发功能类似，Shovel 够可靠、持续地从一个 Broker 中的队列(作为源端，即source)拉取数据并转发至另一个 Broker 中的交换器(作为目的端，即 destination)。
		作为源端的队列和作为目的端的交换器可以同时位于同一个 Broker，也可以位于不同的 Broker 上。Shovel 可以翻译为"铲子"，是一种比较形象的比喻，这个"铲子"可以将消息从一方"铲子"另一方。Shovel 
		行为就像优秀的客户端应用程序能够负责连接源和目的地、负责消息的读写及负责连接失败问题的处理。
		② 搭建步骤 
			A. 开启插件(需要的机器都开启)
				rabbitmq-plugins enable rabbitmq_shovel
				rabbitmq-plugins enable rabbitmq_shovel_management
			B. 原理图(在源头发送的消息直接回进入到目的地队列)
				      消息		 +------------------+     outing.q1    	 +----+
				---------------> | shovel1_exchange | -----------------> | Q1 |
								 +------------------+			   	 	 +----+
																		   ↓
																	   +--------+
				先往Q1和Q2各自发一条消息，当加上shovel之后Q2有两条消息 | Shovel |
																	   +--------+
																		   ↓
					消息		 +------------------+     outing.q2    	 +----+														  
				---------------> | shovel2_exchange | -----------------> | Q2 |
								 +------------------+			   	 	 +----+
			C. 添加 shovel 源和目的地 
				a. 点击 node1 Admin -> 点击 Shovel Manegement -> 选择 Add a new shovel
				b. 输入 name：Q1-to-Q2
				c. Source：选择 AMQP 0.9.1，URI：amqp://admin:2648@hadoop101，Queue：Q1
				d. Destination：选择 AMQP 0.9.1，URI：amqp://admin:2648@hadoop102，Queue：Q2
				e. 点击 Add shove
			D. 点击 Shovel Status，查看状态
					